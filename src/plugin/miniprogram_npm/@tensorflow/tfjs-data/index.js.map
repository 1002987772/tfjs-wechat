{"version":3,"sources":["index.js","dataset.js","iterators/lazy_iterator.js","util/deep_map.js","util/growing_ring_buffer.js","util/ring_buffer.js","datasets/csv_dataset.js","datasets/text_line_dataset.js","readers.js","sources/url_data_source.js","datasource.js","iterators/url_chunk_iterator.js","iterators/file_chunk_iterator.js","iterators/byte_chunk_iterator.js","iterators/string_iterator.js","util/source_util.js","sources/file_data_source.js","version.js"],"names":[],"mappings":";;;;;;;AAAA;AACA;AACA;ACFA,ADGA;ACFA,ADGA;ACFA,ADGA;ACFA,ADGA,AENA;ADIA,ADGA,AENA;ADIA,ADGA,AENA;ADIA,ADGA,AENA,ACHA;AFOA,ADGA,AENA,ACHA;AFOA,ADGA,AENA,ACHA;AFOA,ADGA,AENA,ACHA,ACHA;AHUA,ADGA,AENA,ACHA,ACHA;AHUA,ADGA,AENA,ACHA,ACHA;AHUA,ADGA,AENA,ACHA,ACHA,ACHA;AJaA,ADGA,AENA,ACHA,ACHA,ACHA;AJaA,ADGA,AENA,ACHA,ACHA,ACHA;AJaA,AKfA,ANkBA,AENA,ACHA,ACHA,ACHA;AJaA,AKfA,ANkBA,AENA,ACHA,ACHA,ACHA;AJaA,AKfA,ANkBA,AENA,ACHA,ACHA,ACHA;AJaA,AKfA,ACHA,APqBA,AENA,ACHA,ACHA,ACHA;AJaA,AKfA,ACHA,APqBA,AENA,ACHA,ACHA,ACHA;AJaA,AKfA,ACHA,APqBA,AENA,ACHA,ACHA,ACHA;AJaA,AKfA,ACHA,APqBA,AENA,AMlBA,ALeA,ACHA,ACHA;AJaA,AKfA,ACHA,APqBA,AENA,AMlBA,ALeA,ACHA,ACHA;AJaA,AKfA,ACHA,APqBA,AENA,AMlBA,ALeA,ACHA,ACHA;AJaA,AKfA,ACHA,APqBA,AENA,AMlBA,ACHA,ANkBA,ACHA,ACHA;AJaA,AKfA,ACHA,APqBA,AENA,AMlBA,ACHA,ANkBA,ACHA,ACHA;AJaA,AKfA,ACHA,APqBA,AENA,AMlBA,ACHA,ANkBA,ACHA,ACHA;AJaA,AKfA,ACHA,AGTA,AV8BA,AENA,AMlBA,ACHA,ANkBA,ACHA,ACHA;AJaA,AKfA,ACHA,AGTA,AV8BA,AENA,AMlBA,ACHA,ANkBA,ACHA,ACHA;AJaA,AKfA,ACHA,AGTA,AV8BA,AENA,AMlBA,ACHA,ANkBA,ACHA,ACHA;AJaA,AKfA,ACHA,AGTA,AV8BA,AENA,AS3BA,AHSA,ACHA,ANkBA,ACHA,ACHA;AJaA,AKfA,ACHA,AGTA,AV8BA,AENA,AS3BA,AHSA,ACHA,ANkBA,ACHA,ACHA;AJaA,AKfA,ACHA,AGTA,AV8BA,AENA,AS3BA,AHSA,ACHA,ANkBA,ACHA,ACHA;AJaA,AKfA,ACHA,AGTA,AV8BA,AYpCA,AV8BA,AS3BA,AHSA,ACHA,ANkBA,ACHA,ACHA;AJaA,AKfA,ACHA,AGTA,AENA,AV8BA,AS3BA,AHSA,ACHA,ANkBA,ACHA,ACHA;AJaA,AKfA,ACHA,AGTA,AENA,AV8BA,AS3BA,AHSA,ACHA,ANkBA,ACHA,ACHA;AJaA,AKfA,ACHA,AGTA,AGTA,ADGA,AV8BA,AS3BA,AHSA,ACHA,ANkBA,ACHA,ACHA;AJaA,AKfA,ACHA,AGTA,AGTA,ADGA,AV8BA,AS3BA,AHSA,ACHA,ANkBA,ACHA,ACHA;AJaA,AKfA,ACHA,AGTA,AGTA,ADGA,AV8BA,AS3BA,AHSA,ACHA,ANkBA,ACHA,ACHA;AJaA,AKfA,ACHA,AGTA,AGTA,ADGA,AV8BA,AYpCA,AHSA,AHSA,ACHA,ANkBA,ACHA,ACHA;AJaA,AKfA,ACHA,AGTA,AGTA,ADGA,AV8BA,AYpCA,AHSA,AHSA,ACHA,ANkBA,ACHA,ACHA;AJaA,AKfA,ACHA,AGTA,AGTA,ADGA,AV8BA,AYpCA,AHSA,AHSA,ACHA,ANkBA,ACHA,ACHA;AJaA,AKfA,ACHA,AGTA,AGTA,ADGA,AV8BA,AYpCA,AHSA,AHSA,ACHA,ANkBA,ACHA,ACHA,AU9BA;Ad2CA,AKfA,ACHA,AGTA,AGTA,ADGA,AV8BA,AYpCA,AHSA,AHSA,ACHA,ANkBA,ACHA,ACHA,AU9BA;Ad2CA,AKfA,ACHA,AGTA,AGTA,ADGA,AV8BA,AYpCA,AHSA,AHSA,ACHA,ANkBA,ACHA,ACHA,AU9BA;Ad2CA,AKfA,ACHA,AGTA,AGTA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA,AU9BA;Ad2CA,AKfA,ACHA,AGTA,AGTA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA,AU9BA;Ad2CA,AKfA,ACHA,AGTA,AGTA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA,AU9BA;Ad2CA,AKfA,ACHA,AGTA,AGTA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA,AU9BA,AENA;AhBiDA,AKfA,ACHA,AGTA,AGTA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA,AU9BA,AENA;AhBiDA,AKfA,ACHA,AGTA,AGTA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA,AU9BA,AENA;AhBiDA,AKfA,ACHA,AGTA,AGTA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA,AU9BA,AENA;AhBiDA,AKfA,ACHA,AGTA,AGTA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA,AU9BA,AENA;AhBiDA,AKfA,ACHA,AGTA,AGTA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA,AU9BA,AENA;AhBiDA,AKfA,ACHA,AGTA,AGTA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA,AU9BA,AENA;AhBiDA,AKfA,ACHA,AGTA,AGTA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA,AU9BA;Ad2CA,AKfA,ACHA,AGTA,AGTA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA,AU9BA;Ad2CA,AKfA,ACHA,AGTA,AGTA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA,AU9BA;Ad2CA,AKfA,ACHA,AGTA,AGTA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA,AU9BA;Ad2CA,AKfA,ACHA,AGTA,AGTA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA,AU9BA;Ad2CA,AKfA,ACHA,AGTA,AGTA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA,AU9BA;Ad2CA,AKfA,ACHA,AGTA,AGTA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA,AU9BA;Ad2CA,AKfA,ACHA,AGTA,AGTA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA,AU9BA;Ad2CA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA,AU9BA;Ad2CA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA,AU9BA;Ad2CA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA,AU9BA;Ad2CA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA,AU9BA;Ad2CA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA,AU9BA;Ad2CA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA,AU9BA;Ad2CA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,ACHA,ACHA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,ACHA,AMlBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,AHSA,AHSA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,AQxBA,APqBA,ANkBA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,AQxBA,AbuCA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,AQxBA,AbuCA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,AQxBA,AbuCA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,AQxBA,AbuCA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,AQxBA,AbuCA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,AQxBA,AbuCA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,AQxBA,AbuCA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,AQxBA,AbuCA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,AQxBA,AbuCA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,AQxBA,AbuCA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,AQxBA,AbuCA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,AQxBA,AbuCA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,AQxBA,AbuCA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,AQxBA,AbuCA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,AQxBA,AbuCA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,AQxBA,AbuCA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,AQxBA,AbuCA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,AQxBA,AbuCA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,AQxBA,AbuCA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,ALeA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,ALeA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,ALeA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,ALeA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,ALeA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,ALeA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,ALeA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,ALeA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,ALeA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,ALeA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,ALeA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,ALeA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,ALeA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,ALeA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,ALeA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,ALeA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,ALeA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,ALeA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,ALeA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,ALeA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,ALeA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,ALeA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,ALeA,AENA;AJaA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,ALeA;AFOA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,ALeA;AFOA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,ALeA;AFOA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,ALeA;AFOA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,ALeA;AFOA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,ALeA;AFOA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,ALeA;AFOA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,ALeA;AFOA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,ALeA;AFOA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,ALeA;AFOA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,ALeA;AFOA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,ALeA;AFOA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,ALeA;AFOA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,ALeA;AFOA,AKfA,AOrBA,ADGA,AV8BA,AYpCA,ANkBA,ALeA;AFOA,AKfA,AOrBA,AXiCA,AYpCA,ANkBA,ALeA;AFOA,AKfA,AOrBA,AXiCA,AYpCA,ANkBA,ALeA;AFOA,AKfA,AOrBA,AXiCA,AYpCA,ANkBA,ALeA;AFOA,AKfA,AOrBA,AXiCA,AYpCA,ANkBA,ALeA;AFOA,AKfA,AOrBA,AXiCA,AYpCA,ANkBA,ALeA;AFOA,AKfA,AOrBA,AXiCA,AYpCA,ANkBA,ALeA;AFOA,AKfA,AOrBA,AXiCA,AYpCA,ANkBA,ALeA;AFOA,AKfA,AOrBA,AXiCA,AYpCA,ANkBA,ALeA;AFOA,AKfA,AOrBA,AXiCA,AYpCA,ANkBA,ALeA;AFOA,AKfA,AOrBA,AXiCA,AYpCA,ANkBA,ALeA;AFOA,AKfA,AOrBA,AXiCA,AYpCA,ANkBA,ALeA;AFOA,AKfA,AOrBA,AXiCA,AYpCA,ANkBA,ALeA;AFOA,AKfA,AOrBA,AXiCA,AYpCA,ANkBA,ALeA;AFOA,AKfA,AOrBA,AXiCA,AYpCA,ANkBA,ALeA;AFOA,AKfA,AOrBA,AXiCA,AYpCA,ANkBA,ALeA;AFOA,AKfA,AOrBA,AXiCA,AYpCA,ANkBA,ALeA;AFOA,AKfA,AOrBA,AXiCA,AYpCA,ANkBA,ALeA;AFOA,AKfA,AOrBA,AXiCA,AYpCA,ANkBA,ALeA;AFOA,AKfA,AOrBA,AXiCA,AYpCA,ANkBA,ALeA;AFOA,AKfA,AOrBA,AXiCA,AYpCA,ANkBA,ALeA;AFOA,AKfA,AOrBA,AXiCA,AYpCA,ANkBA,ALeA;AFOA,AKfA,AOrBA,AXiCA,AMlBA,ALeA;AFOA,AKfA,AOrBA,AXiCA,AMlBA,ALeA;AFOA,AKfA,AOrBA,AXiCA,AMlBA,ALeA;AFOA,AKfA,AOrBA,AXiCA,AMlBA,ALeA;AFOA,AKfA,AOrBA,AXiCA,AMlBA,ALeA;AFOA,AKfA,AOrBA,AXiCA,AMlBA,ALeA;AFOA,AKfA,AOrBA,AXiCA,AMlBA,ALeA;AFOA,AKfA,AOrBA,AXiCA,AMlBA,ALeA;AFOA,AKfA,AOrBA,AXiCA,AMlBA,ALeA;AFOA,AKfA,AOrBA,AXiCA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,AMlBA,ALeA;AFOA,AKfA,AJYA,ACHA;AFOA,AKfA,AJYA,ACHA;AFOA,AKfA,AJYA,ACHA;AFOA,AKfA,AJYA,ACHA;AFOA,AKfA,AJYA,ACHA;AFOA,AKfA,AJYA,ACHA;AFOA,AKfA,AJYA,ACHA;AFOA,AKfA,AJYA,ACHA;AFOA,AKfA,AJYA,ACHA;AFOA,AKfA,AJYA,ACHA;AFOA,AKfA,AJYA,ACHA;AFOA,AKfA,AJYA,ACHA;AFOA,AKfA,AJYA,ACHA;AFOA,AKfA,AJYA,ACHA;AFOA,AKfA,AJYA,ACHA;AFOA,AKfA,AJYA,ACHA;AFOA,AKfA,AJYA,ACHA;AFOA,AKfA,AJYA,ACHA;AFOA,AKfA,AJYA,ACHA;AFOA,AKfA,AJYA,ACHA;AFOA,AKfA,AJYA,ACHA;AFOA,AKfA,AJYA,ACHA;AFOA,AKfA,AJYA,ACHA;AFOA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,AKfA,AJYA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,ACHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","file":"index.js","sourcesContent":["\"use strict\";\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar dataset_1 = require(\"./dataset\");\nexports.array = dataset_1.array;\nexports.Dataset = dataset_1.Dataset;\nexports.zip = dataset_1.zip;\nvar csv_dataset_1 = require(\"./datasets/csv_dataset\");\nexports.CSVDataset = csv_dataset_1.CSVDataset;\nvar text_line_dataset_1 = require(\"./datasets/text_line_dataset\");\nexports.TextLineDataset = text_line_dataset_1.TextLineDataset;\nvar readers_1 = require(\"./readers\");\nexports.csv = readers_1.csv;\nexports.func = readers_1.func;\nexports.generator = readers_1.generator;\nvar file_data_source_1 = require(\"./sources/file_data_source\");\nexports.FileDataSource = file_data_source_1.FileDataSource;\nvar url_data_source_1 = require(\"./sources/url_data_source\");\nexports.URLDataSource = url_data_source_1.URLDataSource;\nvar version_1 = require(\"./version\");\nexports.version_data = version_1.version;\n//# sourceMappingURL=index.js.map","\"use strict\";\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tf = require(\"@tensorflow/tfjs-core\");\nvar seedrandom = require(\"seedrandom\");\nvar lazy_iterator_1 = require(\"./iterators/lazy_iterator\");\nvar deep_map_1 = require(\"./util/deep_map\");\n// TODO(soergel): consider vectorized operations within the pipeline.\n/**\n * Represents a potentially large list of independent data elements (typically\n * 'samples' or 'examples').\n *\n * A 'data example' may be a primitive, an array, a map from string keys to\n * values, or any nested structure of these.\n *\n * A `Dataset` represents an ordered collection of elements, together with a\n * chain of transformations to be performed on those elements. Each\n * transformation is a method of `Dataset` that returns another `Dataset`, so\n * these may be chained, e.g.\n * `const processedDataset = rawDataset.filter(...).map(...).batch(...)`.\n *\n * Data loading and transformation is done in a lazy, streaming fashion.  The\n * dataset may be iterated over multiple times; each iteration starts the data\n * loading anew and recapitulates the transformations.\n *\n * A `Dataset` is typically processed as a stream of unbatched examples --i.e.,\n * its transformations are applied one example at a time. Batching produces a\n * new `Dataset` where each element is a batch. Batching should usually come\n * last in a pipeline, because data transformations are easier to express on a\n * per-example basis than on a per-batch basis.\n *\n * The following code examples are calling `await dataset.forEachAsync(...)` to\n * iterate once over the entire dataset in order to print out the data.\n */\n/** @doc {heading: 'Data', subheading: 'Classes', namespace: 'data'} */\nvar Dataset = /** @class */ (function () {\n    function Dataset() {\n        this.size = null;\n    }\n    // TODO(soergel): Make Datasets report whether repeated iterator() calls\n    // produce the same result (e.g., reading from a file) or different results\n    // (e.g., from the webcam).  Currently we don't make this distinction but it\n    // could be important for the user to know.\n    // abstract isDeterministic(): boolean;\n    /**\n     * Groups elements into batches.\n     *\n     * It is assumed that each of the incoming dataset elements has the same\n     * structure-- i.e. the same set of keys at each location in an object\n     * hierarchy.  For each key, the resulting `Dataset` provides a batched\n     * element collecting all of the incoming values for that key.\n     *\n     *  * Incoming primitives are grouped into a 1-D Tensor.\n     *  * Incoming Tensors are grouped into a new Tensor where the 0'th axis is\n     *    the batch dimension.\n     *  * Incoming arrays are converted to Tensor and then batched.\n     *  * A nested array is interpreted as an n-D Tensor, so the batched result\n     *    has n+1 dimensions.\n     *  * An array that cannot be converted to Tensor produces an error.\n     *\n     * If an array should not be batched as a unit, it should first be converted\n     * to an object with integer keys.\n     *\n     * Here are a few examples:\n     *\n     * Batch a dataset of numbers:\n     * ```js\n     * const a = tf.data.array([1, 2, 3, 4, 5, 6, 7, 8]).batch(4);\n     * await a.forEachAsync(e => e.print());\n     * ```\n     *\n     * Batch a dataset of arrays:\n     * ```js\n     * const b = tf.data.array([[1], [2], [3], [4], [5], [6], [7], [8]]).batch(4);\n     * await b.forEachAsync(e => e.print());\n     * ```\n     *\n     * Batch a dataset of objects:\n     * ```js\n     * const c = tf.data.array([{a: 1, b: 11}, {a: 2, b: 12}, {a: 3, b: 13},\n     *   {a: 4, b: 14}, {a: 5, b: 15}, {a: 6, b: 16}, {a: 7, b: 17},\n     *   {a: 8, b: 18}]).batch(4);\n     * await c.forEachAsync(e => {\n     *   console.log('{');\n     *   for(var key in e) {\n     *     console.log(key+':');\n     *     e[key].print();\n     *   }\n     *   console.log('}');\n     * })\n     * ```\n     *\n     * @param batchSize The number of elements desired per batch.\n     * @param smallLastBatch Whether to emit the final batch when it has fewer\n     *   than batchSize elements. Default true.\n     * @returns A `Dataset`, from which a stream of batches can be obtained.\n     */\n    /** @doc {heading: 'Data', subheading: 'Classes'} */\n    Dataset.prototype.batch = function (batchSize, smallLastBatch) {\n        var _this = this;\n        if (smallLastBatch === void 0) { smallLastBatch = true; }\n        var base = this;\n        tf.util.assert(batchSize > 0, function () { return \"batchSize needs to be positive, but it is\\n      \" + batchSize; });\n        var size;\n        if (this.size === Infinity || this.size == null) {\n            // If the size of this dataset is infinity or null, the new size keeps the\n            // same.\n            size = this.size;\n        }\n        else if (smallLastBatch) {\n            // If the size of this dataset is known and include small last batch, the\n            // new size is full batch count plus last batch.\n            size = Math.ceil(this.size / batchSize);\n        }\n        else {\n            // If the size of this dataset is known and not include small last batch,\n            // the new size is full batch count.\n            size = Math.floor(this.size / batchSize);\n        }\n        return datasetFromIteratorFn(function () { return __awaiter(_this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0: return [4 /*yield*/, base.iterator()];\n                    case 1: return [2 /*return*/, (_a.sent())\n                            .columnMajorBatch(batchSize, smallLastBatch, deepBatchConcat)];\n                }\n            });\n        }); }, size);\n    };\n    /**\n     * Concatenates this `Dataset` with another.\n     *\n     * ```js\n     * const a = tf.data.array([1, 2, 3]);\n     * const b = tf.data.array([4, 5, 6]);\n     * const c = a.concatenate(b);\n     * await c.forEachAsync(e => console.log(e));\n     * ```\n     *\n     * @param dataset A `Dataset` to be concatenated onto this one.\n     * @returns A `Dataset`.\n     */\n    /** @doc {heading: 'Data', subheading: 'Classes'} */\n    Dataset.prototype.concatenate = function (dataset) {\n        var _this = this;\n        var base = this;\n        var size;\n        if (this.size === Infinity || dataset.size === Infinity) {\n            // If the size of any of these two dataset is infinity, new size is\n            // infinity.\n            size = Infinity;\n        }\n        else if (this.size != null && dataset.size != null) {\n            // If the size of both datasets are known and not infinity, new size is\n            // sum the size of these two datasets.\n            size = this.size + dataset.size;\n        }\n        else {\n            // If neither of these two datasets has infinite size and any of these two\n            // datasets' size is null, the new size is null.\n            size = null;\n        }\n        return datasetFromIteratorFn(function () { return __awaiter(_this, void 0, void 0, function () { var _a, _b; return __generator(this, function (_c) {\n            switch (_c.label) {\n                case 0: return [4 /*yield*/, base.iterator()];\n                case 1:\n                    _b = (_a = (_c.sent())).concatenate;\n                    return [4 /*yield*/, dataset.iterator()];\n                case 2: return [2 /*return*/, _b.apply(_a, [_c.sent()])];\n            }\n        }); }); }, size);\n    };\n    /**\n     * Filters this dataset according to `predicate`.\n     *\n     * ```js\n     * const a = tf.data.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n     *   .filter(x => x%2 === 0);\n     * await a.forEachAsync(e => console.log(e));\n     * ```\n     *\n     * @param predicate A function mapping a dataset element to a boolean or a\n     * `Promise` for one.\n     *\n     * @returns A `Dataset` of elements for which the predicate was true.\n     */\n    /** @doc {heading: 'Data', subheading: 'Classes'} */\n    Dataset.prototype.filter = function (predicate) {\n        var _this = this;\n        var base = this;\n        var size;\n        if (this.size === Infinity) {\n            // If the size of this dataset is infinity, new size is infinity\n            size = Infinity;\n        }\n        else {\n            // If this dataset has limited elements, new size is null because it might\n            // exhausted randomly.\n            size = null;\n        }\n        return datasetFromIteratorFn(function () { return __awaiter(_this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0: return [4 /*yield*/, base.iterator()];\n                    case 1: return [2 /*return*/, (_a.sent()).filter(function (x) { return tf.tidy(function () { return predicate(x); }); })];\n                }\n            });\n        }); }, size);\n    };\n    /**\n     * Apply a function to every element of the dataset.\n     *\n     * After the function is applied to a dataset element, any Tensors contained\n     * within that element are disposed.\n     *\n     * ```js\n     * const a = tf.data.array([1, 2, 3]);\n     * await a.forEachAsync(e => console.log(e));\n     * ```\n     *\n     * @param f A function to apply to each dataset element.\n     * @returns A `Promise` that resolves after all elements have been processed.\n     */\n    /** @doc {heading: 'Data', subheading: 'Classes'} */\n    Dataset.prototype.forEachAsync = function (f) {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0: return [4 /*yield*/, this.iterator()];\n                    case 1: return [2 /*return*/, (_a.sent()).forEachAsync(f)];\n                }\n            });\n        });\n    };\n    /** @deprecated Please use `dataset.forEachAsync()` instead. */\n    Dataset.prototype.forEach = function (f) {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                tf.deprecationWarn('dataset.forEach() is deprecated and will be removed. ' +\n                    'Please use dataset.forEachAsync() instead');\n                return [2 /*return*/, this.forEachAsync(f)];\n            });\n        });\n    };\n    /**\n     * Maps this dataset through a 1-to-1 transform.\n     *\n     * ```js\n     * const a = tf.data.array([1, 2, 3]).map(x => x*x);\n     * await a.forEachAsync(e => console.log(e));\n     * ```\n     *\n     * @param transform A function mapping a dataset element to a transformed\n     *   dataset element.\n     *\n     * @returns A `Dataset` of transformed elements.\n     */\n    /** @doc {heading: 'Data', subheading: 'Classes'} */\n    Dataset.prototype.map = function (transform) {\n        var _this = this;\n        var base = this;\n        return datasetFromIteratorFn(function () { return __awaiter(_this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0: return [4 /*yield*/, base.iterator()];\n                    case 1: return [2 /*return*/, (_a.sent()).map(function (x) { return tf.tidy(function () { return transform(x); }); })];\n                }\n            });\n        }); }, this.size);\n    };\n    /**\n     * Maps this dataset through an async 1-to-1 transform.\n     *\n     * ```js\n     * const a = tf.data.array([1, 2, 3]).map(x => new Promise(function(resolve){\n     *  resolve(x*x);\n     * }));\n     * await a.forEachAsync(e => e.then(function(value){\n     *  console.log(value);\n     * }));\n     * ```\n     *\n     * @param transform A function mapping a dataset element to a `Promise` for a\n     *   transformed dataset element.  This transform is responsible for disposing\n     *   any intermediate `Tensor`s, i.e. by wrapping its computation in\n     *   `tf.tidy()`; that cannot be automated here (as it is in the synchronous\n     *   `map()` case).\n     *\n     * @returns A `Dataset` of transformed elements.\n     */\n    /** @doc {heading: 'Data', subheading: 'Classes'} */\n    Dataset.prototype.mapAsync = function (transform) {\n        var _this = this;\n        var base = this;\n        return datasetFromIteratorFn(function () { return __awaiter(_this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0: return [4 /*yield*/, base.iterator()];\n                    case 1: return [2 /*return*/, (_a.sent()).mapAsync(transform)];\n                }\n            });\n        }); }, this.size);\n    };\n    /**\n     *  Creates a `Dataset` that prefetches elements from this dataset.\n     *\n     * @param bufferSize: An integer specifying the number of elements to be\n     *   prefetched.\n     * @returns A `Dataset`.\n     */\n    /** @doc {heading: 'Data', subheading: 'Classes'} */\n    Dataset.prototype.prefetch = function (bufferSize) {\n        var _this = this;\n        if (bufferSize == null) {\n            throw new RangeError('`Dataset.prefetch()` requires bufferSize to be specified.');\n        }\n        var base = this;\n        return datasetFromIteratorFn(function () { return __awaiter(_this, void 0, void 0, function () { return __generator(this, function (_a) {\n            switch (_a.label) {\n                case 0: return [4 /*yield*/, base.iterator()];\n                case 1: return [2 /*return*/, (_a.sent()).prefetch(bufferSize)];\n            }\n        }); }); }, this.size);\n    };\n    /**\n     * Repeats this dataset `count` times.\n     *\n     * NOTE: If this dataset is a function of global state (e.g. a random number\n     * generator), then different repetitions may produce different elements.\n     *\n     * ```js\n     * const a = tf.data.array([1, 2, 3]).repeat(3);\n     * await a.forEachAsync(e => console.log(e));\n     * ```\n     *\n     * @param count: (Optional) An integer, representing the number of times\n     *   the dataset should be repeated. The default behavior (if `count` is\n     *   `undefined` or negative) is for the dataset be repeated indefinitely.\n     * @returns A `Dataset`.\n     */\n    /** @doc {heading: 'Data', subheading: 'Classes'} */\n    Dataset.prototype.repeat = function (count) {\n        var _this = this;\n        var base = this;\n        var size;\n        if (this.size != null && count > 0) {\n            // If this dataset has size and count is positive, new size is current\n            // size multiply count. This also covers the case that current size is\n            // infinity.\n            size = this.size * count;\n        }\n        else if (count === 0) {\n            // If count is 0, new size is 0.\n            size = 0;\n        }\n        else if (this.size != null && (count === undefined || count < 0)) {\n            // If this dataset has size and count is undefined or negative, the\n            // dataset will be repeated indefinitely and new size is infinity.\n            size = Infinity;\n        }\n        else {\n            // If the size of this dataset is null, the new dataset's size is null.\n            size = null;\n        }\n        return datasetFromIteratorFn(function () { return __awaiter(_this, void 0, void 0, function () {\n            var iteratorIterator;\n            var _this = this;\n            return __generator(this, function (_a) {\n                iteratorIterator = lazy_iterator_1.iteratorFromFunction(function () { return __awaiter(_this, void 0, void 0, function () { var _a; return __generator(this, function (_b) {\n                    switch (_b.label) {\n                        case 0:\n                            _a = {};\n                            return [4 /*yield*/, base.iterator()];\n                        case 1: return [2 /*return*/, (_a.value = _b.sent(), _a.done = false, _a)];\n                    }\n                }); }); });\n                return [2 /*return*/, lazy_iterator_1.iteratorFromConcatenated(iteratorIterator.take(count))];\n            });\n        }); }, size);\n    };\n    /**\n     * Creates a `Dataset` that skips `count` initial elements from this dataset.\n     *\n     * ```js\n     * const a = tf.data.array([1, 2, 3, 4, 5, 6]).skip(3);\n     * await a.forEachAsync(e => console.log(e));\n     * ```\n     *\n     * @param count: The number of elements of this dataset that should be skipped\n     *   to form the new dataset.  If `count` is greater than the size of this\n     *   dataset, the new dataset will contain no elements.  If `count`\n     *   is `undefined` or negative, skips the entire dataset.\n     *\n     * @returns A `Dataset`.\n     */\n    /** @doc {heading: 'Data', subheading: 'Classes'} */\n    Dataset.prototype.skip = function (count) {\n        var _this = this;\n        var base = this;\n        var size;\n        if (this.size != null && count >= 0 && this.size >= count) {\n            // If the size of this dataset is greater than count, the new dataset's\n            // size is current size minus skipped size.This also covers the case that\n            // current size is infinity.\n            size = this.size - count;\n        }\n        else if (this.size != null &&\n            (this.size < count || count === undefined || count < 0)) {\n            // If the size of this dataset is smaller than count, or count is\n            // undefined or negative, skips the entire dataset and the new size is 0.\n            size = 0;\n        }\n        else {\n            // If the size of this dataset is null, the new dataset's size is null.\n            size = null;\n        }\n        return datasetFromIteratorFn(function () { return __awaiter(_this, void 0, void 0, function () { return __generator(this, function (_a) {\n            switch (_a.label) {\n                case 0: return [4 /*yield*/, base.iterator()];\n                case 1: return [2 /*return*/, (_a.sent()).skip(count)];\n            }\n        }); }); }, size);\n    };\n    /**\n     * Pseudorandomly shuffles the elements of this dataset. This is done in a\n     * streaming manner, by sampling from a given number of prefetched elements.\n     *\n     * ```js\n     * const a = tf.data.array([1, 2, 3, 4, 5, 6]).shuffle(3);\n     * await a.forEachAsync(e => console.log(e));\n     * ```\n     *\n     * @param bufferSize: An integer specifying the number of elements from this\n     *   dataset from which the new dataset will sample.\n     * @param seed: (Optional) An integer specifying the random seed that will\n     *   be used to create the distribution.\n     * @param reshuffleEachIteration: (Optional) A boolean, which if true\n     *   indicates that the dataset should be pseudorandomly reshuffled each time\n     *   it is iterated over. If false, elements will be returned in the same\n     *   shuffled order on each iteration. (Defaults to `true`.)\n     * @returns A `Dataset`.\n     */\n    /** @doc {heading: 'Data', subheading: 'Classes'} */\n    Dataset.prototype.shuffle = function (bufferSize, seed, reshuffleEachIteration) {\n        var _this = this;\n        if (reshuffleEachIteration === void 0) { reshuffleEachIteration = true; }\n        if (bufferSize == null || bufferSize < 0) {\n            if (this.size == null) {\n                throw new RangeError('`Dataset.shuffle()` requires bufferSize to be specified.');\n            }\n            else {\n                throw new RangeError('`Dataset.shuffle()` requires bufferSize to be specified.  ' +\n                    'If your data fits in main memory (for regular JS objects), ' +\n                    'and/or GPU memory (for `tf.Tensor`s), consider setting ' +\n                    (\"bufferSize to the dataset size (\" + this.size + \" elements)\"));\n            }\n        }\n        var base = this;\n        var random = seedrandom.alea(seed || tf.util.now().toString());\n        return datasetFromIteratorFn(function () { return __awaiter(_this, void 0, void 0, function () {\n            var seed2;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        seed2 = random.int32();\n                        if (reshuffleEachIteration) {\n                            seed2 += random.int32();\n                        }\n                        return [4 /*yield*/, base.iterator()];\n                    case 1: return [2 /*return*/, (_a.sent()).shuffle(bufferSize, seed2.toString())];\n                }\n            });\n        }); }, this.size);\n    };\n    /**\n     * Creates a `Dataset` with at most `count` initial elements from this\n     * dataset.\n     *\n     * ```js\n     * const a = tf.data.array([1, 2, 3, 4, 5, 6]).take(3);\n     * await a.forEachAsync(e => console.log(e));\n     * ```\n     *\n     * @param count: The number of elements of this dataset that should be taken\n     *   to form the new dataset.  If `count` is `undefined` or negative, or if\n     *   `count` is greater than the size of this dataset, the new dataset will\n     *   contain all elements of this dataset.\n     * @returns A `Dataset`.\n     */\n    /** @doc {heading: 'Data', subheading: 'Classes'} */\n    Dataset.prototype.take = function (count) {\n        var _this = this;\n        var base = this;\n        var size;\n        if (this.size != null && this.size > count) {\n            // If the size of this dataset is greater than count, the new dataset's\n            // size is count.\n            size = count;\n        }\n        else if (this.size != null && this.size <= count) {\n            // If the size of this dataset is equal or smaller than count, the new\n            // dataset's size is the size of this dataset.\n            size = this.size;\n        }\n        else {\n            // If the size of this dataset is null, the new dataset's size is null.\n            size = null;\n        }\n        return datasetFromIteratorFn(function () { return __awaiter(_this, void 0, void 0, function () { return __generator(this, function (_a) {\n            switch (_a.label) {\n                case 0: return [4 /*yield*/, base.iterator()];\n                case 1: return [2 /*return*/, (_a.sent()).take(count)];\n            }\n        }); }); }, size);\n    };\n    /**\n     * Collect all elements of this dataset into an array.\n     *\n     * Obviously this will succeed only for small datasets that fit in memory.\n     * Useful for testing and generally should be avoided if possible.\n     *\n     * ```js\n     * const a = tf.data.array([1, 2, 3, 4, 5, 6]);\n     * console.log(await a.toArray());\n     * ```\n     *\n     * @returns A Promise for an array of elements, which will resolve\n     *   when a new stream has been obtained and fully consumed.\n     */\n    /** @doc {heading: 'Data', subheading: 'Classes'} */\n    Dataset.prototype.toArray = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        if (this.size === Infinity) {\n                            throw new Error('Can not convert infinite data stream to array.');\n                        }\n                        return [4 /*yield*/, this.iterator()];\n                    case 1: return [2 /*return*/, (_a.sent()).toArray()];\n                }\n            });\n        });\n    };\n    /**\n     * Collect all elements of this dataset into an array with prefetching 100\n     * elements. This is useful for testing, because the prefetch changes the\n     * order in which the Promises are resolved along the processing pipeline.\n     * This may help expose bugs where results are dependent on the order of\n     * Promise resolution rather than on the logical order of the stream (i.e.,\n     * due to hidden mutable state).\n     *\n     * @returns A Promise for an array of elements, which will resolve\n     *   when a new stream has been obtained and fully consumed.\n     */\n    Dataset.prototype.toArrayForTest = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        if (this.size === Infinity) {\n                            throw new Error('Can not convert infinite data stream to array.');\n                        }\n                        return [4 /*yield*/, this.iterator()];\n                    case 1: return [2 /*return*/, (_a.sent()).toArrayForTest()];\n                }\n            });\n        });\n    };\n    // TODO(soergel): deep sharded shuffle, where supported\n    Dataset.MAX_BUFFER_SIZE = 10000;\n    return Dataset;\n}());\nexports.Dataset = Dataset;\n/**\n * Create a `Dataset` defined by a provided iterator() function.\n *\n * ```js\n * let i = -1;\n * const func = () =>\n *    ++i < 5 ? {value: i, done: false} : {value: null, done: true};\n * const iter = tf.data.iteratorFromFunction(func);\n * const ds = tf.data.datasetFromIteratorFn(iter);\n * await ds.forEachAsync(e => console.log(e));\n * ```\n */\nfunction datasetFromIteratorFn(iteratorFn, size) {\n    if (size === void 0) { size = null; }\n    return new /** @class */ (function (_super) {\n        __extends(class_1, _super);\n        function class_1() {\n            var _this = _super !== null && _super.apply(this, arguments) || this;\n            _this.size = size;\n            return _this;\n        }\n        /*\n         * Provide a new stream of elements.  Note this will also start new streams\n         * from any underlying `Dataset`s.\n         */\n        class_1.prototype.iterator = function () {\n            return __awaiter(this, void 0, void 0, function () {\n                return __generator(this, function (_a) {\n                    return [2 /*return*/, iteratorFn()];\n                });\n            });\n        };\n        return class_1;\n    }(Dataset))();\n}\nexports.datasetFromIteratorFn = datasetFromIteratorFn;\n/**\n * Create a `Dataset` from an array of elements.\n *\n * Create a Dataset from an array of objects:\n * ```js\n * const a = tf.data.array([{'item': 1}, {'item': 2}, {'item': 3}]);\n * await a.forEachAsync(e => console.log(e));\n * ```\n *\n * Create a Dataset from an array of numbers:\n * ```js\n * const a = tf.data.array([4, 5, 6]);\n * await a.forEachAsync(e => console.log(e));\n * ```\n * @param items An array of elements that will be parsed as items in a dataset.\n */\n/** @doc {heading: 'Data', subheading: 'Creation', namespace: 'data'} */\nfunction array(items) {\n    var _this = this;\n    return datasetFromIteratorFn(function () { return __awaiter(_this, void 0, void 0, function () { return __generator(this, function (_a) {\n        return [2 /*return*/, lazy_iterator_1.iteratorFromItems(items)];\n    }); }); }, items.length);\n}\nexports.array = array;\n/**\n * Create a `Dataset` by zipping together an array, dict, or nested\n * structure of `Dataset`s (and perhaps additional constants).\n * The underlying datasets must provide elements in a consistent order such that\n * they correspond.\n *\n * The number of elements in the resulting dataset is the same as the size of\n * the smallest dataset in datasets.\n *\n * The nested structure of the `datasets` argument determines the\n * structure of elements in the resulting iterator.\n *\n * Note this means that, given an array of two datasets that produce dict\n * elements, the result is a dataset that produces elements that are arrays\n * of two dicts:\n *\n * Zip an array of datasets:\n * ```js\n * console.log('Zip two datasets of objects:');\n * const ds1 = tf.data.array([{a: 1}, {a: 2}, {a: 3}]);\n * const ds2 = tf.data.array([{b: 4}, {b: 5}, {b: 6}]);\n * const ds3 = tf.data.zip([ds1, ds2]);\n * await ds3.forEachAsync(e => console.log(JSON.stringify(e)));\n *\n * // If the goal is to merge the dicts in order to produce elements like\n * // {a: ..., b: ...}, this requires a second step such as:\n * console.log('Merge the objects:');\n * const ds4 = ds3.map(x => {return {a: x[0].a, b: x[1].b}});\n * await ds4.forEachAsync(e => console.log(e));\n * ```\n *\n * Zip a dict of datasets:\n * ```js\n * const a = tf.data.array([{a: 1}, {a: 2}, {a: 3}]);\n * const b = tf.data.array([{b: 4}, {b: 5}, {b: 6}]);\n * const c = tf.data.zip({c: a, d: b});\n * await c.forEachAsync(e => console.log(JSON.stringify(e)));\n * ```\n */\n/** @doc {heading: 'Data', subheading: 'Operations', namespace: 'data'} */\nfunction zip(datasets) {\n    var _this = this;\n    // manually type-check the argument for JS users\n    if (!deep_map_1.isIterable(datasets)) {\n        throw new Error('The argument to zip() must be an object or array.');\n    }\n    var size;\n    if (Array.isArray(datasets)) {\n        for (var i = 0; i < datasets.length; i++) {\n            size = size == null ? datasets[i].size :\n                Math.min(size, datasets[i].size);\n        }\n    }\n    else if (datasets instanceof Object) {\n        for (var ds in datasets) {\n            size = size == null ? datasets[ds].size :\n                Math.min(size, datasets[ds].size);\n        }\n    }\n    return datasetFromIteratorFn(function () { return __awaiter(_this, void 0, void 0, function () {\n        var streams;\n        return __generator(this, function (_a) {\n            switch (_a.label) {\n                case 0: return [4 /*yield*/, deep_map_1.deepMapAndAwaitAll(datasets, function (d) {\n                        if (d instanceof Dataset) {\n                            return { value: d.iterator(), recurse: false };\n                        }\n                        else if (deep_map_1.isIterable(d)) {\n                            return { value: null, recurse: true };\n                        }\n                        else {\n                            throw new Error('Leaves of the structure passed to zip() must be Datasets, ' +\n                                'not primitives.');\n                        }\n                    })];\n                case 1:\n                    streams = _a.sent();\n                    return [2 /*return*/, lazy_iterator_1.iteratorFromZipped(streams, lazy_iterator_1.ZipMismatchMode.SHORTEST)];\n            }\n        });\n    }); }, size);\n}\nexports.zip = zip;\n/**\n * A zip function for use with deepZip, passed via the columnMajorBatch call.\n *\n * Accepts an array of identically-structured nested elements and either batches\n * them (if they are primitives, numeric arrays, or Tensors) or requests\n * recursion (if not).\n */\n// tslint:disable-next-line:no-any\nfunction deepBatchConcat(rows) {\n    if (rows === null) {\n        return null;\n    }\n    // use the first item to decide whether to recurse or batch here.\n    var exampleRow = rows[0];\n    if (deep_map_1.canTensorify(exampleRow)) {\n        // rows is an array of primitives, Tensors, or arrays.  Batch them.\n        var value = batchConcat(rows);\n        return { value: value, recurse: false };\n    }\n    // the example row is an object, so recurse into it.\n    return { value: null, recurse: true };\n}\n/**\n * Assembles a list of same-shaped numbers, number arrays, or Tensors\n * into a single new Tensor where axis 0 is the batch dimension.\n */\nfunction batchConcat(arrays) {\n    if (arrays.length === 0) {\n        // We can't return an empty Tensor because we don't know the element shape.\n        throw new Error('Can\\'t make a batch of zero elements.');\n    }\n    if (arrays[0] instanceof tf.Tensor) {\n        // Input is an array of Tensors\n        return tf.stack(arrays);\n    }\n    else {\n        // Input is a possibly-nested array of numbers.\n        return tf.tensor(arrays);\n    }\n}\n//# sourceMappingURL=dataset.js.map","\"use strict\";\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tf = require(\"@tensorflow/tfjs-core\");\nvar seedrandom = require(\"seedrandom\");\nvar deep_map_1 = require(\"../util/deep_map\");\nvar growing_ring_buffer_1 = require(\"../util/growing_ring_buffer\");\nvar ring_buffer_1 = require(\"../util/ring_buffer\");\n// Here we implement a simple asynchronous iterator.\n// This lets us avoid using either third-party stream libraries or\n// recent TypeScript language support requiring polyfills.\n/**\n * Create a `LazyIterator` from an array of items.\n */\nfunction iteratorFromItems(items) {\n    return new ArrayIterator(items);\n}\nexports.iteratorFromItems = iteratorFromItems;\n/**\n * Create a `LazyIterator` of incrementing integers.\n */\nfunction iteratorFromIncrementing(start) {\n    var i = start;\n    return iteratorFromFunction(function () { return ({ value: i++, done: false }); });\n}\nexports.iteratorFromIncrementing = iteratorFromIncrementing;\n/**\n * Create a `LazyIterator` from a function.\n *\n * ```js\n * let i = -1;\n * const func = () =>\n *    ++i < 5 ? {value: i, done: false} : {value: null, done: true};\n * const iter = tf.data.iteratorFromFunction(func);\n * await iter.forEachAsync(e => console.log(e));\n * ```\n *\n * @param func A function that produces data on each call.\n */\nfunction iteratorFromFunction(func) {\n    return new FunctionCallIterator(func);\n}\nexports.iteratorFromFunction = iteratorFromFunction;\n/**\n * Create a `LazyIterator` by concatenating underlying streams, which are\n * themselves provided as a stream.\n *\n * This can also be thought of as a \"stream flatten\" operation.\n *\n * @param baseIterators A stream of streams to be concatenated.\n * @param baseErrorHandler An optional function that can intercept `Error`s\n *   raised during a `next()` call on the base stream.  This function can decide\n *   whether the error should be propagated, whether the error should be\n *   ignored, or whether the base stream should be terminated.\n */\nfunction iteratorFromConcatenated(baseIterators, baseErrorHandler) {\n    return new ChainedIterator(baseIterators, baseErrorHandler);\n}\nexports.iteratorFromConcatenated = iteratorFromConcatenated;\n/**\n * Create a `LazyIterator` by concatenating streams produced by calling a\n * stream-generating function a given number of times.\n *\n * Since a `LazyIterator` is read-once, it cannot be repeated, but this\n * function can be used to achieve a similar effect:\n *\n *   LazyIterator.ofConcatenatedFunction(() => new MyIterator(), 6);\n *\n * @param iteratorFunc: A function that produces a new stream on each call.\n * @param count: The number of times to call the function.\n * @param baseErrorHandler An optional function that can intercept `Error`s\n *   raised during a `next()` call on the base stream.  This function can decide\n *   whether the error should be propagated, whether the error should be\n *   ignored, or whether the base stream should be terminated.\n */\nfunction iteratorFromConcatenatedFunction(iteratorFunc, count, baseErrorHandler) {\n    return iteratorFromConcatenated(iteratorFromFunction(iteratorFunc).take(count), baseErrorHandler);\n}\nexports.iteratorFromConcatenatedFunction = iteratorFromConcatenatedFunction;\n/**\n * Create a `LazyIterator` by zipping together an array, dict, or nested\n * structure of `LazyIterator`s (and perhaps additional constants).\n *\n * The underlying streams must provide elements in a consistent order such\n * that they correspond.\n *\n * Typically, the underlying streams should have the same number of\n * elements. If they do not, the behavior is determined by the\n * `mismatchMode` argument.\n *\n * The nested structure of the `iterators` argument determines the\n * structure of elements in the resulting iterator.\n *\n * @param iterators: An array or object containing LazyIterators at the\n * leaves.\n * @param mismatchMode: Determines what to do when one underlying iterator\n * is exhausted before the others.  `ZipMismatchMode.FAIL` (the default)\n * causes an error to be thrown in this case.  `ZipMismatchMode.SHORTEST`\n * causes the zipped iterator to terminate with the furst underlying\n * streams, so elements remaining on the longer streams are ignored.\n * `ZipMismatchMode.LONGEST` causes the zipped stream to continue, filling\n * in nulls for the exhausted streams, until all streams are exhausted.\n */\nfunction iteratorFromZipped(iterators, mismatchMode) {\n    if (mismatchMode === void 0) { mismatchMode = ZipMismatchMode.FAIL; }\n    return new ZipIterator(iterators, mismatchMode);\n}\nexports.iteratorFromZipped = iteratorFromZipped;\n/**\n * An asynchronous iterator, providing lazy access to a potentially\n * unbounded stream of elements.\n *\n * Iterator can be obtained from a dataset:\n * `const iter = await dataset.iterator();`\n */\nvar LazyIterator = /** @class */ (function () {\n    function LazyIterator() {\n    }\n    /**\n     * Collect all remaining elements of a bounded stream into an array.\n     * Obviously this will succeed only for small streams that fit in memory.\n     * Useful for testing.\n     *\n     * @returns A Promise for an array of stream elements, which will resolve\n     *   when the stream is exhausted.\n     */\n    LazyIterator.prototype.toArray = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var result, x;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        result = [];\n                        return [4 /*yield*/, this.next()];\n                    case 1:\n                        x = _a.sent();\n                        _a.label = 2;\n                    case 2:\n                        if (!!x.done) return [3 /*break*/, 4];\n                        result.push(x.value);\n                        return [4 /*yield*/, this.next()];\n                    case 3:\n                        x = _a.sent();\n                        return [3 /*break*/, 2];\n                    case 4: return [2 /*return*/, result];\n                }\n            });\n        });\n    };\n    /**\n     * Collect all elements of this dataset into an array with prefetching 100\n     * elements. This is useful for testing, because the prefetch changes the\n     * order in which the Promises are resolved along the processing pipeline.\n     * This may help expose bugs where results are dependent on the order of\n     * Promise resolution rather than on the logical order of the stream (i.e.,\n     * due to hidden mutable state).\n     *\n     * @returns A Promise for an array of stream elements, which will resolve\n     *   when the stream is exhausted.\n     */\n    LazyIterator.prototype.toArrayForTest = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var stream, result, x;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        stream = this.prefetch(100);\n                        result = [];\n                        return [4 /*yield*/, stream.next()];\n                    case 1:\n                        x = _a.sent();\n                        _a.label = 2;\n                    case 2:\n                        if (!!x.done) return [3 /*break*/, 4];\n                        result.push(x.value);\n                        return [4 /*yield*/, stream.next()];\n                    case 3:\n                        x = _a.sent();\n                        return [3 /*break*/, 2];\n                    case 4: return [2 /*return*/, result];\n                }\n            });\n        });\n    };\n    /**\n     * Draw items from the stream until it is exhausted.\n     *\n     * This can be useful when the stream has side effects but no output.  In\n     * that case, calling this function guarantees that the stream will be\n     * fully processed.\n     */\n    LazyIterator.prototype.resolveFully = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var x;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0: return [4 /*yield*/, this.next()];\n                    case 1:\n                        x = _a.sent();\n                        _a.label = 2;\n                    case 2:\n                        if (!!x.done) return [3 /*break*/, 4];\n                        return [4 /*yield*/, this.next()];\n                    case 3:\n                        x = _a.sent();\n                        return [3 /*break*/, 2];\n                    case 4: return [2 /*return*/];\n                }\n            });\n        });\n    };\n    /**\n     * Draw items from the stream until it is exhausted, or a predicate fails.\n     *\n     * This can be useful when the stream has side effects but no output.  In\n     * that case, calling this function guarantees that the stream will be\n     * fully processed.\n     */\n    LazyIterator.prototype.resolveWhile = function (predicate) {\n        return __awaiter(this, void 0, void 0, function () {\n            var x, shouldContinue;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0: return [4 /*yield*/, this.next()];\n                    case 1:\n                        x = _a.sent();\n                        shouldContinue = predicate(x.value);\n                        _a.label = 2;\n                    case 2:\n                        if (!((!x.done) && shouldContinue)) return [3 /*break*/, 4];\n                        return [4 /*yield*/, this.next()];\n                    case 3:\n                        x = _a.sent();\n                        shouldContinue = predicate(x.value);\n                        return [3 /*break*/, 2];\n                    case 4: return [2 /*return*/];\n                }\n            });\n        });\n    };\n    /**\n     * Handles errors thrown on this stream using a provided handler function.\n     *\n     * @param handler A function that handles any `Error` thrown during a `next()`\n     *   call and returns true if the stream should continue (dropping the failed\n     *   call) or false if the stream should quietly terminate.  If the handler\n     *   itself throws (or rethrows) an `Error`, that will be propagated.\n     *\n     * @returns A `LazyIterator` of elements passed through from upstream,\n     *   possibly filtering or terminating on upstream `next()` calls that\n     *   throw an `Error`.\n     */\n    LazyIterator.prototype.handleErrors = function (handler) {\n        return new ErrorHandlingLazyIterator(this, handler);\n    };\n    // TODO(soergel): Implement reduce() etc.\n    /**\n     * Filters this stream according to `predicate`.\n     *\n     * @param predicate A function mapping a stream element to a boolean or a\n     * `Promise` for one.\n     *\n     * @returns A `LazyIterator` of elements for which the predicate was true.\n     */\n    LazyIterator.prototype.filter = function (predicate) {\n        return new FilterIterator(this, predicate);\n    };\n    /**\n     * Maps this stream through a 1-to-1 transform.\n     *\n     * @param transform A function mapping a stream element to a transformed\n     *   element.\n     *\n     * @returns A `LazyIterator` of transformed elements.\n     */\n    LazyIterator.prototype.map = function (transform) {\n        return new MapIterator(this, transform);\n    };\n    /**\n     * Maps this stream through an async 1-to-1 transform.\n     *\n     * @param transform A function mapping a stream element to a `Promise` for a\n     *   transformed stream element.\n     *\n     * @returns A `LazyIterator` of transformed elements.\n     */\n    LazyIterator.prototype.mapAsync = function (transform) {\n        return new AsyncMapIterator(this, transform);\n    };\n    /**\n     * Maps this stream through a 1-to-1 transform, forcing serial execution.\n     *\n     * @param transform A function mapping a stream element to a transformed\n     *   element.\n     *\n     * @returns A `LazyIterator` of transformed elements.\n     */\n    LazyIterator.prototype.serialMapAsync = function (transform) {\n        return new AsyncMapIterator(this, transform).serial();\n    };\n    /**\n     * Maps this stream through a 1-to-many transform.\n     *\n     * @param transform A function mapping a stream element to an array of\n     *   transformed elements.\n     *\n     * @returns A `DataStream` of transformed elements.\n     */\n    LazyIterator.prototype.flatmap = function (transform) {\n        return new FlatmapIterator(this, transform);\n    };\n    /**\n     * Apply a function to every element of the stream.\n     *\n     * @param f A function to apply to each stream element.\n     */\n    LazyIterator.prototype.forEachAsync = function (f) {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                return [2 /*return*/, this.map(f).resolveFully()];\n            });\n        });\n    };\n    /**\n     * Apply a function to every element of the stream, forcing serial execution.\n     *\n     * @param f A function to apply to each stream element.  Should return 'true'\n     *   to indicate that the stream should continue, or 'false' to cause it to\n     *   terminate.\n     */\n    LazyIterator.prototype.serialForEach = function (f) {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                return [2 /*return*/, this.serialMapAsync(f).resolveWhile(function (x) { return (x === true); })];\n            });\n        });\n    };\n    /**\n     * Groups elements into batches, represented as arrays of elements.\n     *\n     * We can think of the elements of this iterator as 'rows' (even if they are\n     * nested structures).  By the same token, consecutive values for a given\n     * key within the elements form a 'column'.  This matches the usual sense of\n     * 'row' and 'column' when processing tabular data (e.g., parsing a CSV).\n     *\n     * Thus, \"Row-major\" means that the resulting batch is simply a collection of\n     * rows: `[row1, row2, row3, ...]`.  This is contrast to the column-major\n     * form, which is needed for vectorized computation.\n     *\n     * @param batchSize The number of elements desired per batch.\n     * @param smallLastBatch Whether to emit the final batch when it has fewer\n     *   than batchSize elements. Default true.\n     * @returns A `LazyIterator` of batches of elements, represented as arrays\n     *   of the original element type.\n     */\n    LazyIterator.prototype.rowMajorBatch = function (batchSize, smallLastBatch) {\n        if (smallLastBatch === void 0) { smallLastBatch = true; }\n        return new RowMajorBatchIterator(this, batchSize, smallLastBatch);\n    };\n    /**\n     * Groups elements into batches, represented in column-major form.\n     *\n     * We can think of the elements of this iterator as 'rows' (even if they are\n     * nested structures).  By the same token, consecutive values for a given\n     * key within the elements form a 'column'.  This matches the usual sense of\n     * 'row' and 'column' when processing tabular data (e.g., parsing a CSV).\n     *\n     * Thus, \"column-major\" means that the resulting batch is a (potentially\n     * nested) structure representing the columns.  Each column entry, then,\n     * contains a collection of the values found in that column for a range of\n     * input elements.  This representation allows for vectorized computation, in\n     * contrast to the row-major form.\n     *\n     * The inputs should all have the same nested structure (i.e., of arrays and\n     * dicts).  The result is a single object with the same nested structure,\n     * where the leaves are arrays collecting the values of the inputs at that\n     * location (or, optionally, the result of a custom function applied to those\n     * arrays).\n     *\n     * @param batchSize The number of elements desired per batch.\n     * @param smallLastBatch Whether to emit the final batch when it has fewer\n     *   than batchSize elements. Default true.\n     * @param zipFn: (optional) A function that expects an array of elements at a\n     *   single node of the object tree, and returns a `DeepMapResult`.  The\n     *   `DeepMapResult` either provides a result value for that node (i.e.,\n     *   representing the subtree), or indicates that the node should be processed\n     *   recursively.  The default zipFn recurses as far as possible and places\n     *   arrays at the leaves.\n     * @returns A `LazyIterator` of batches of elements, represented as an object\n     *   with collections at the leaves.\n     */\n    LazyIterator.prototype.columnMajorBatch = function (batchSize, smallLastBatch, \n    // tslint:disable-next-line:no-any\n    zipFn) {\n        if (smallLastBatch === void 0) { smallLastBatch = true; }\n        if (zipFn === void 0) { zipFn = deep_map_1.zipToList; }\n        // First collect the desired number of input elements as a row-major batch.\n        var rowBatches = this.rowMajorBatch(batchSize, smallLastBatch);\n        // Now 'rotate' or 'pivot' the data, collecting all values from each column\n        // in the batch (i.e., for each key within the elements) into an array.\n        return rowBatches.map(function (x) { return deep_map_1.deepZip(x, zipFn); });\n    };\n    /**\n     * Concatenate this `LazyIterator` with another.\n     *\n     * @param iterator A `LazyIterator` to be concatenated onto this one.\n     * @param baseErrorHandler An optional function that can intercept `Error`s\n     *   raised during a `next()` call on the base stream.  This function can\n     *   decide whether the error should be propagated, whether the error should\n     *   be ignored, or whether the base stream should be terminated.\n     * @returns A `LazyIterator`.\n     */\n    LazyIterator.prototype.concatenate = function (iterator, baseErrorHandler) {\n        return new ChainedIterator(iteratorFromItems([this, iterator]), baseErrorHandler);\n    };\n    /**\n     * Limits this stream to return at most `count` items.\n     *\n     * @param count The maximum number of items to provide from the stream. If\n     * a negative or undefined value is given, the entire stream is returned\n     *   unaltered.\n     */\n    LazyIterator.prototype.take = function (count) {\n        if (count < 0 || count == null) {\n            return this;\n        }\n        return new TakeIterator(this, count);\n    };\n    /**\n     * Skips the first `count` items in this stream.\n     *\n     * @param count The number of items to skip.  If a negative or undefined\n     * value is given, the entire stream is returned unaltered.\n     */\n    LazyIterator.prototype.skip = function (count) {\n        if (count < 0 || count == null) {\n            return this;\n        }\n        return new SkipIterator(this, count);\n    };\n    /**\n     * Prefetch the first `bufferSize` items in this stream.\n     *\n     * Note this prefetches Promises, but makes no guarantees about when those\n     * Promises resolve.\n     *\n     * @param bufferSize: An integer specifying the number of elements to be\n     *   prefetched.\n     */\n    LazyIterator.prototype.prefetch = function (bufferSize) {\n        return new PrefetchIterator(this, bufferSize);\n    };\n    // TODO(soergel): deep sharded shuffle, where supported\n    /**\n     * Randomly shuffles the elements of this stream.\n     *\n     * @param bufferSize: An integer specifying the number of elements from\n     * this stream from which the new stream will sample.\n     * @param seed: (Optional.) An integer specifying the random seed that\n     * will be used to create the distribution.\n     */\n    LazyIterator.prototype.shuffle = function (windowSize, seed) {\n        return new ShuffleIterator(this, windowSize, seed);\n    };\n    /**\n     * Force an iterator to execute serially: each next() call will await the\n     * prior one, so that they cannot execute concurrently.\n     */\n    LazyIterator.prototype.serial = function () {\n        return new SerialIterator(this);\n    };\n    return LazyIterator;\n}());\nexports.LazyIterator = LazyIterator;\n// ============================================================================\n// The following private classes serve to implement the chainable methods\n// on LazyIterator.  Unfortunately they can't be placed in separate files,\n// due to resulting trouble with circular imports.\n// ============================================================================\n// Iterators that just extend LazyIterator directly\n// ============================================================================\nvar ArrayIterator = /** @class */ (function (_super) {\n    __extends(ArrayIterator, _super);\n    function ArrayIterator(items) {\n        var _this = _super.call(this) || this;\n        _this.items = items;\n        _this.trav = 0;\n        return _this;\n    }\n    ArrayIterator.prototype.summary = function () {\n        return \"Array of \" + this.items.length + \" items\";\n    };\n    ArrayIterator.prototype.next = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var item, result;\n            return __generator(this, function (_a) {\n                if (this.trav >= this.items.length) {\n                    return [2 /*return*/, { value: null, done: true }];\n                }\n                item = this.items[this.trav];\n                if (item instanceof tf.Tensor) {\n                    result = tf.clone(item);\n                }\n                else {\n                    result = item;\n                }\n                this.trav++;\n                return [2 /*return*/, { value: result, done: false }];\n            });\n        });\n    };\n    return ArrayIterator;\n}(LazyIterator));\nvar FunctionCallIterator = /** @class */ (function (_super) {\n    __extends(FunctionCallIterator, _super);\n    function FunctionCallIterator(nextFn) {\n        var _this = _super.call(this) || this;\n        _this.nextFn = nextFn;\n        return _this;\n    }\n    FunctionCallIterator.prototype.summary = function () {\n        return \"Function call\";\n    };\n    FunctionCallIterator.prototype.next = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                try {\n                    return [2 /*return*/, this.nextFn()];\n                }\n                catch (e) {\n                    // Modify the error message but leave the stack trace intact\n                    e.message =\n                        \"Error thrown while iterating through a dataset: \" + e.message;\n                    throw e;\n                }\n                return [2 /*return*/];\n            });\n        });\n    };\n    return FunctionCallIterator;\n}(LazyIterator));\nvar SerialIterator = /** @class */ (function (_super) {\n    __extends(SerialIterator, _super);\n    function SerialIterator(upstream) {\n        var _this = _super.call(this) || this;\n        _this.upstream = upstream;\n        _this.lastRead = Promise.resolve({ value: null, done: false });\n        return _this;\n    }\n    SerialIterator.prototype.summary = function () {\n        return this.upstream.summary() + \" -> Serial\";\n    };\n    SerialIterator.prototype.next = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var _this = this;\n            return __generator(this, function (_a) {\n                // This sets this.lastRead to a new Promise right away, as opposed to\n                // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n                // would not work because this.nextRead would be updated only after the\n                // promise resolves.\n                this.lastRead = this.lastRead.then(function () { return _this.serialNext(); });\n                return [2 /*return*/, this.lastRead];\n            });\n        });\n    };\n    SerialIterator.prototype.serialNext = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                return [2 /*return*/, this.upstream.next()];\n            });\n        });\n    };\n    return SerialIterator;\n}(LazyIterator));\nvar SkipIterator = /** @class */ (function (_super) {\n    __extends(SkipIterator, _super);\n    function SkipIterator(upstream, maxCount) {\n        var _this = _super.call(this) || this;\n        _this.upstream = upstream;\n        _this.maxCount = maxCount;\n        // Local state that should not be clobbered by out-of-order execution.\n        _this.count = 0;\n        _this.lastRead = Promise.resolve({ value: null, done: false });\n        return _this;\n    }\n    SkipIterator.prototype.summary = function () {\n        return this.upstream.summary() + \" -> Skip\";\n    };\n    SkipIterator.prototype.next = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var _this = this;\n            return __generator(this, function (_a) {\n                // This sets this.lastRead to a new Promise right away, as opposed to\n                // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n                // would not work because this.nextRead would be updated only after the\n                // promise resolves.\n                this.lastRead = this.lastRead.then(function () { return _this.serialNext(); });\n                return [2 /*return*/, this.lastRead];\n            });\n        });\n    };\n    SkipIterator.prototype.serialNext = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var skipped;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        if (!(this.count++ < this.maxCount)) return [3 /*break*/, 2];\n                        return [4 /*yield*/, this.upstream.next()];\n                    case 1:\n                        skipped = _a.sent();\n                        // short-circuit if upstream is already empty\n                        if (skipped.done) {\n                            return [2 /*return*/, skipped];\n                        }\n                        tf.dispose(skipped.value);\n                        return [3 /*break*/, 0];\n                    case 2: return [2 /*return*/, this.upstream.next()];\n                }\n            });\n        });\n    };\n    return SkipIterator;\n}(LazyIterator));\nvar TakeIterator = /** @class */ (function (_super) {\n    __extends(TakeIterator, _super);\n    function TakeIterator(upstream, maxCount) {\n        var _this = _super.call(this) || this;\n        _this.upstream = upstream;\n        _this.maxCount = maxCount;\n        _this.count = 0;\n        return _this;\n    }\n    TakeIterator.prototype.summary = function () {\n        return this.upstream.summary() + \" -> Take\";\n    };\n    TakeIterator.prototype.next = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                if (this.count++ >= this.maxCount) {\n                    return [2 /*return*/, { value: null, done: true }];\n                }\n                return [2 /*return*/, this.upstream.next()];\n            });\n        });\n    };\n    return TakeIterator;\n}(LazyIterator));\n// Note this batch just groups items into row-wise element arrays.\n// Rotating these to a column-wise representation happens only at the dataset\n// level.\nvar RowMajorBatchIterator = /** @class */ (function (_super) {\n    __extends(RowMajorBatchIterator, _super);\n    function RowMajorBatchIterator(upstream, batchSize, enableSmallLastBatch) {\n        if (enableSmallLastBatch === void 0) { enableSmallLastBatch = true; }\n        var _this = _super.call(this) || this;\n        _this.upstream = upstream;\n        _this.batchSize = batchSize;\n        _this.enableSmallLastBatch = enableSmallLastBatch;\n        _this.lastRead = Promise.resolve({ value: null, done: false });\n        return _this;\n    }\n    RowMajorBatchIterator.prototype.summary = function () {\n        return this.upstream.summary() + \" -> RowMajorBatch\";\n    };\n    RowMajorBatchIterator.prototype.next = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var _this = this;\n            return __generator(this, function (_a) {\n                // This sets this.lastRead to a new Promise right away, as opposed to\n                // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n                // would not work because this.nextRead would be updated only after the\n                // promise resolves.\n                this.lastRead = this.lastRead.then(function () { return _this.serialNext(); });\n                return [2 /*return*/, this.lastRead];\n            });\n        });\n    };\n    RowMajorBatchIterator.prototype.serialNext = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var batch, item;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        batch = [];\n                        _a.label = 1;\n                    case 1:\n                        if (!(batch.length < this.batchSize)) return [3 /*break*/, 3];\n                        return [4 /*yield*/, this.upstream.next()];\n                    case 2:\n                        item = _a.sent();\n                        if (item.done) {\n                            if (this.enableSmallLastBatch && batch.length > 0) {\n                                return [2 /*return*/, { value: batch, done: false }];\n                            }\n                            return [2 /*return*/, { value: null, done: true }];\n                        }\n                        batch.push(item.value);\n                        return [3 /*break*/, 1];\n                    case 3: return [2 /*return*/, { value: batch, done: false }];\n                }\n            });\n        });\n    };\n    return RowMajorBatchIterator;\n}(LazyIterator));\nvar FilterIterator = /** @class */ (function (_super) {\n    __extends(FilterIterator, _super);\n    function FilterIterator(upstream, predicate) {\n        var _this = _super.call(this) || this;\n        _this.upstream = upstream;\n        _this.predicate = predicate;\n        _this.lastRead = Promise.resolve({ value: null, done: false });\n        return _this;\n    }\n    FilterIterator.prototype.summary = function () {\n        return this.upstream.summary() + \" -> Filter\";\n    };\n    FilterIterator.prototype.next = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var _this = this;\n            return __generator(this, function (_a) {\n                // This sets this.lastRead to a new Promise right away, as opposed to\n                // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n                // would not work because this.nextRead would be updated only after the\n                // promise resolves.\n                this.lastRead = this.lastRead.then(function () { return _this.serialNext(); });\n                return [2 /*return*/, this.lastRead];\n            });\n        });\n    };\n    FilterIterator.prototype.serialNext = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var item;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        if (!true) return [3 /*break*/, 2];\n                        return [4 /*yield*/, this.upstream.next()];\n                    case 1:\n                        item = _a.sent();\n                        if (item.done || this.predicate(item.value)) {\n                            return [2 /*return*/, item];\n                        }\n                        tf.dispose(item.value);\n                        return [3 /*break*/, 0];\n                    case 2: return [2 /*return*/];\n                }\n            });\n        });\n    };\n    return FilterIterator;\n}(LazyIterator));\nvar MapIterator = /** @class */ (function (_super) {\n    __extends(MapIterator, _super);\n    function MapIterator(upstream, transform) {\n        var _this = _super.call(this) || this;\n        _this.upstream = upstream;\n        _this.transform = transform;\n        return _this;\n    }\n    MapIterator.prototype.summary = function () {\n        return this.upstream.summary() + \" -> Map\";\n    };\n    MapIterator.prototype.next = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var item, inputTensors, mapped, outputTensors, _i, inputTensors_1, t;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0: return [4 /*yield*/, this.upstream.next()];\n                    case 1:\n                        item = _a.sent();\n                        if (item.done) {\n                            return [2 /*return*/, { value: null, done: true }];\n                        }\n                        inputTensors = tf.tensor_util.getTensorsInContainer(item.value);\n                        mapped = this.transform(item.value);\n                        outputTensors = tf.tensor_util.getTensorsInContainer(mapped);\n                        // TODO(soergel) faster intersection\n                        // TODO(soergel) move to tf.disposeExcept(in, out)?\n                        for (_i = 0, inputTensors_1 = inputTensors; _i < inputTensors_1.length; _i++) {\n                            t = inputTensors_1[_i];\n                            if (!tf.tensor_util.isTensorInList(t, outputTensors)) {\n                                t.dispose();\n                            }\n                        }\n                        return [2 /*return*/, { value: mapped, done: false }];\n                }\n            });\n        });\n    };\n    return MapIterator;\n}(LazyIterator));\nvar ErrorHandlingLazyIterator = /** @class */ (function (_super) {\n    __extends(ErrorHandlingLazyIterator, _super);\n    function ErrorHandlingLazyIterator(upstream, handler) {\n        var _this = _super.call(this) || this;\n        _this.upstream = upstream;\n        _this.handler = handler;\n        _this.count = 0;\n        _this.lastRead = Promise.resolve({ value: null, done: false });\n        return _this;\n    }\n    ErrorHandlingLazyIterator.prototype.summary = function () {\n        return this.upstream.summary() + \" -> handleErrors\";\n    };\n    ErrorHandlingLazyIterator.prototype.next = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var _this = this;\n            return __generator(this, function (_a) {\n                // This sets this.lastRead to a new Promise right away, as opposed to\n                // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n                // would not work because this.nextRead would be updated only after the\n                // promise resolves.\n                this.lastRead = this.lastRead.then(function () { return _this.serialNext(); });\n                return [2 /*return*/, this.lastRead];\n            });\n        });\n    };\n    ErrorHandlingLazyIterator.prototype.serialNext = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var e_1;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        if (!true) return [3 /*break*/, 5];\n                        _a.label = 1;\n                    case 1:\n                        _a.trys.push([1, 3, , 4]);\n                        return [4 /*yield*/, this.upstream.next()];\n                    case 2: return [2 /*return*/, _a.sent()];\n                    case 3:\n                        e_1 = _a.sent();\n                        if (!this.handler(e_1)) {\n                            return [2 /*return*/, { value: null, done: true }];\n                        }\n                        return [3 /*break*/, 4];\n                    case 4: return [3 /*break*/, 0];\n                    case 5: return [2 /*return*/];\n                }\n            });\n        });\n    };\n    return ErrorHandlingLazyIterator;\n}(LazyIterator));\nvar AsyncMapIterator = /** @class */ (function (_super) {\n    __extends(AsyncMapIterator, _super);\n    function AsyncMapIterator(upstream, transform) {\n        var _this = _super.call(this) || this;\n        _this.upstream = upstream;\n        _this.transform = transform;\n        return _this;\n    }\n    AsyncMapIterator.prototype.summary = function () {\n        return this.upstream.summary() + \" -> AsyncMap\";\n    };\n    AsyncMapIterator.prototype.next = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var item, inputTensors, mapped, outputTensors, _i, inputTensors_2, t;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0: return [4 /*yield*/, this.upstream.next()];\n                    case 1:\n                        item = _a.sent();\n                        if (item.done) {\n                            return [2 /*return*/, { value: null, done: true }];\n                        }\n                        inputTensors = tf.tensor_util.getTensorsInContainer(item.value);\n                        return [4 /*yield*/, this.transform(item.value)];\n                    case 2:\n                        mapped = _a.sent();\n                        outputTensors = tf.tensor_util.getTensorsInContainer(mapped);\n                        // TODO(soergel) faster intersection\n                        // TODO(soergel) move to tf.disposeExcept(in, out)?\n                        for (_i = 0, inputTensors_2 = inputTensors; _i < inputTensors_2.length; _i++) {\n                            t = inputTensors_2[_i];\n                            if (!tf.tensor_util.isTensorInList(t, outputTensors)) {\n                                t.dispose();\n                            }\n                        }\n                        return [2 /*return*/, { value: mapped, done: false }];\n                }\n            });\n        });\n    };\n    return AsyncMapIterator;\n}(LazyIterator));\n// Iterators that maintain a queue of pending items\n// ============================================================================\n/**\n * A base class for transforming streams that operate by maintaining an\n * output queue of elements that are ready to return via next().  This is\n * commonly required when the transformation is 1-to-many:  A call to next()\n * may trigger a call to the underlying stream, which will produce many\n * mapped elements of this stream-- of which we need to return only one, so\n * we have to queue the rest.\n */\nvar OneToManyIterator = /** @class */ (function (_super) {\n    __extends(OneToManyIterator, _super);\n    function OneToManyIterator() {\n        var _this = _super.call(this) || this;\n        _this.outputQueue = new growing_ring_buffer_1.GrowingRingBuffer();\n        _this.lastRead = Promise.resolve({ value: null, done: false });\n        return _this;\n    }\n    OneToManyIterator.prototype.next = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var _this = this;\n            return __generator(this, function (_a) {\n                // This sets this.lastRead to a new Promise right away, as opposed to\n                // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n                // would not work because this.nextRead would be updated only after the\n                // promise resolves.\n                this.lastRead = this.lastRead.then(function () { return _this.serialNext(); });\n                return [2 /*return*/, this.lastRead];\n            });\n        });\n    };\n    OneToManyIterator.prototype.serialNext = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        if (!(this.outputQueue.length() === 0)) return [3 /*break*/, 2];\n                        return [4 /*yield*/, this.pump()];\n                    case 1:\n                        // TODO(soergel): consider parallel reads.\n                        if (!(_a.sent())) {\n                            return [2 /*return*/, { value: null, done: true }];\n                        }\n                        return [3 /*break*/, 0];\n                    case 2: return [2 /*return*/, { value: this.outputQueue.shift(), done: false }];\n                }\n            });\n        });\n    };\n    return OneToManyIterator;\n}(LazyIterator));\nexports.OneToManyIterator = OneToManyIterator;\nvar FlatmapIterator = /** @class */ (function (_super) {\n    __extends(FlatmapIterator, _super);\n    function FlatmapIterator(upstream, transform) {\n        var _this = _super.call(this) || this;\n        _this.upstream = upstream;\n        _this.transform = transform;\n        return _this;\n    }\n    FlatmapIterator.prototype.summary = function () {\n        return this.upstream.summary() + \" -> Flatmap\";\n    };\n    FlatmapIterator.prototype.pump = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var item, inputTensors, mappedArray, outputTensors, _i, inputTensors_3, t;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0: return [4 /*yield*/, this.upstream.next()];\n                    case 1:\n                        item = _a.sent();\n                        if (item.done) {\n                            return [2 /*return*/, false];\n                        }\n                        inputTensors = tf.tensor_util.getTensorsInContainer(item.value);\n                        mappedArray = this.transform(item.value);\n                        outputTensors = tf.tensor_util.getTensorsInContainer(mappedArray);\n                        this.outputQueue.pushAll(mappedArray);\n                        // TODO(soergel) faster intersection, and deduplicate outputTensors\n                        // TODO(soergel) move to tf.disposeExcept(in, out)?\n                        for (_i = 0, inputTensors_3 = inputTensors; _i < inputTensors_3.length; _i++) {\n                            t = inputTensors_3[_i];\n                            if (!tf.tensor_util.isTensorInList(t, outputTensors)) {\n                                t.dispose();\n                            }\n                        }\n                        return [2 /*return*/, true];\n                }\n            });\n        });\n    };\n    return FlatmapIterator;\n}(OneToManyIterator));\n/**\n * Provides a `LazyIterator` that concatenates a stream of underlying\n * streams.\n *\n * Doing this in a concurrency-safe way requires some trickery.  In\n * particular, we want this stream to return the elements from the\n * underlying streams in the correct order according to when next() was\n * called, even if the resulting Promises resolve in a different order.\n */\nvar ChainedIterator = /** @class */ (function (_super) {\n    __extends(ChainedIterator, _super);\n    function ChainedIterator(iterators, baseErrorHandler) {\n        var _this = _super.call(this) || this;\n        _this.baseErrorHandler = baseErrorHandler;\n        // Strict Promise execution order:\n        // a next() call may not even begin until the previous one completes.\n        _this.lastRead = null;\n        // Local state that should not be clobbered by out-of-order execution.\n        _this.iterator = null;\n        _this.moreIterators = iterators;\n        return _this;\n    }\n    ChainedIterator.prototype.summary = function () {\n        var upstreamSummaries = 'TODO: fill in upstream of chained summaries';\n        return upstreamSummaries + \" -> Chained\";\n    };\n    ChainedIterator.prototype.next = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                this.lastRead = this.readFromChain(this.lastRead);\n                return [2 /*return*/, this.lastRead];\n            });\n        });\n    };\n    ChainedIterator.prototype.readFromChain = function (lastRead) {\n        return __awaiter(this, void 0, void 0, function () {\n            var iteratorResult, itemResult;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0: \n                    // Must await on the previous read since the previous read may have advanced\n                    // the stream of streams, from which we need to read.\n                    // This is unfortunate since we can't parallelize reads. Which means\n                    // prefetching of chained streams is a no-op.\n                    // One solution is to prefetch immediately upstream of this.\n                    return [4 /*yield*/, lastRead];\n                    case 1:\n                        // Must await on the previous read since the previous read may have advanced\n                        // the stream of streams, from which we need to read.\n                        // This is unfortunate since we can't parallelize reads. Which means\n                        // prefetching of chained streams is a no-op.\n                        // One solution is to prefetch immediately upstream of this.\n                        _a.sent();\n                        if (!(this.iterator == null)) return [3 /*break*/, 3];\n                        return [4 /*yield*/, this.moreIterators.next()];\n                    case 2:\n                        iteratorResult = _a.sent();\n                        if (iteratorResult.done) {\n                            // No more streams to stream from.\n                            return [2 /*return*/, { value: null, done: true }];\n                        }\n                        this.iterator = iteratorResult.value;\n                        if (this.baseErrorHandler != null) {\n                            this.iterator = this.iterator.handleErrors(this.baseErrorHandler);\n                        }\n                        _a.label = 3;\n                    case 3: return [4 /*yield*/, this.iterator.next()];\n                    case 4:\n                        itemResult = _a.sent();\n                        if (itemResult.done) {\n                            this.iterator = null;\n                            return [2 /*return*/, this.readFromChain(lastRead)];\n                        }\n                        return [2 /*return*/, itemResult];\n                }\n            });\n        });\n    };\n    return ChainedIterator;\n}(LazyIterator));\nexports.ChainedIterator = ChainedIterator;\nvar ZipMismatchMode;\n(function (ZipMismatchMode) {\n    ZipMismatchMode[ZipMismatchMode[\"FAIL\"] = 0] = \"FAIL\";\n    ZipMismatchMode[ZipMismatchMode[\"SHORTEST\"] = 1] = \"SHORTEST\";\n    ZipMismatchMode[ZipMismatchMode[\"LONGEST\"] = 2] = \"LONGEST\"; // use nulls for exhausted streams; use up the longest stream.\n})(ZipMismatchMode = exports.ZipMismatchMode || (exports.ZipMismatchMode = {}));\n/**\n * Provides a `LazyIterator` that zips together an array, dict, or nested\n * structure of `LazyIterator`s (and perhaps additional constants).\n *\n * The underlying streams must provide elements in a consistent order such\n * that they correspond.\n *\n * Typically, the underlying streams should have the same number of\n * elements. If they do not, the behavior is determined by the\n * `mismatchMode` argument.\n *\n * The nested structure of the `iterators` argument determines the\n * structure of elements in the resulting iterator.\n *\n * Doing this in a concurrency-safe way requires some trickery.  In\n * particular, we want this stream to return the elements from the\n * underlying streams in the correct order according to when next() was\n * called, even if the resulting Promises resolve in a different order.\n *\n * @param iterators: An array or object containing LazyIterators at the\n * leaves.\n * @param mismatchMode: Determines what to do when one underlying iterator\n * is exhausted before the others.  `ZipMismatchMode.FAIL` (the default)\n * causes an error to be thrown in this case.  `ZipMismatchMode.SHORTEST`\n * causes the zipped iterator to terminate with the furst underlying\n * streams, so elements remaining on the longer streams are ignored.\n * `ZipMismatchMode.LONGEST` causes the zipped stream to continue, filling\n * in nulls for the exhausted streams, until all streams are exhausted.\n */\nvar ZipIterator = /** @class */ (function (_super) {\n    __extends(ZipIterator, _super);\n    function ZipIterator(iterators, mismatchMode) {\n        if (mismatchMode === void 0) { mismatchMode = ZipMismatchMode.FAIL; }\n        var _this = _super.call(this) || this;\n        _this.iterators = iterators;\n        _this.mismatchMode = mismatchMode;\n        _this.count = 0;\n        _this.currentPromise = null;\n        return _this;\n    }\n    ZipIterator.prototype.summary = function () {\n        var upstreamSummaries = 'TODO: fill in upstream of zip summaries';\n        return \"{\" + upstreamSummaries + \"} -> Zip\";\n    };\n    ZipIterator.prototype.nextState = function (afterState) {\n        return __awaiter(this, void 0, void 0, function () {\n            function getNext(container) {\n                if (container instanceof LazyIterator) {\n                    var result = container.next();\n                    return {\n                        value: result.then(function (x) {\n                            numIterators++;\n                            if (x.done) {\n                                iteratorsDone++;\n                            }\n                            return x.value;\n                        }),\n                        recurse: false\n                    };\n                }\n                else {\n                    return { value: null, recurse: true };\n                }\n            }\n            var numIterators, iteratorsDone, mapped;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0: \n                    // This chaining ensures that the underlying next() are not even called\n                    // before the previous ones have resolved.\n                    return [4 /*yield*/, afterState];\n                    case 1:\n                        // This chaining ensures that the underlying next() are not even called\n                        // before the previous ones have resolved.\n                        _a.sent();\n                        numIterators = 0;\n                        iteratorsDone = 0;\n                        return [4 /*yield*/, deep_map_1.deepMapAndAwaitAll(this.iterators, getNext)];\n                    case 2:\n                        mapped = _a.sent();\n                        if (numIterators === iteratorsDone) {\n                            // The streams have all ended.\n                            return [2 /*return*/, { value: null, done: true }];\n                        }\n                        if (iteratorsDone > 0) {\n                            switch (this.mismatchMode) {\n                                case ZipMismatchMode.FAIL:\n                                    throw new Error('Zipped streams should have the same length. ' +\n                                        (\"Mismatched at element \" + this.count + \".\"));\n                                case ZipMismatchMode.SHORTEST:\n                                    return [2 /*return*/, { value: null, done: true }];\n                                case ZipMismatchMode.LONGEST:\n                                default:\n                                // Continue.  The exhausted streams already produced value: null.\n                            }\n                        }\n                        this.count++;\n                        return [2 /*return*/, { value: mapped, done: false }];\n                }\n            });\n        });\n    };\n    ZipIterator.prototype.next = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        this.currentPromise = this.nextState(this.currentPromise);\n                        return [4 /*yield*/, this.currentPromise];\n                    case 1: return [2 /*return*/, (_a.sent())];\n                }\n            });\n        });\n    };\n    return ZipIterator;\n}(LazyIterator));\n// Iterators that maintain a ring buffer of pending promises\n// ============================================================================\n/**\n * A stream that prefetches a given number of items from an upstream source,\n * returning them in FIFO order.\n *\n * Note this prefetches Promises, but makes no guarantees about when those\n * Promises resolve.\n */\nvar PrefetchIterator = /** @class */ (function (_super) {\n    __extends(PrefetchIterator, _super);\n    function PrefetchIterator(upstream, bufferSize) {\n        var _this = _super.call(this) || this;\n        _this.upstream = upstream;\n        _this.bufferSize = bufferSize;\n        _this.buffer = new ring_buffer_1.RingBuffer(bufferSize);\n        return _this;\n    }\n    PrefetchIterator.prototype.summary = function () {\n        return this.upstream.summary() + \" -> Prefetch\";\n    };\n    /**\n     * Refill the prefetch buffer.  Returns only after the buffer is full, or\n     * the upstream source is exhausted.\n     */\n    PrefetchIterator.prototype.refill = function () {\n        while (!this.buffer.isFull()) {\n            var v = this.upstream.next();\n            this.buffer.push(v);\n        }\n    };\n    PrefetchIterator.prototype.next = function () {\n        this.refill();\n        // This shift will never throw an error because the buffer is always\n        // full after a refill. If the stream is exhausted, the buffer will be\n        // full of Promises that will resolve to the end-of-stream signal.\n        return this.buffer.shift();\n    };\n    return PrefetchIterator;\n}(LazyIterator));\nexports.PrefetchIterator = PrefetchIterator;\n/**\n * A stream that performs a sliding-window random shuffle on an upstream\n * source. This is like a `PrefetchIterator` except that the items are\n * returned in randomized order.  Mixing naturally improves as the buffer\n * size increases.\n */\nvar ShuffleIterator = /** @class */ (function (_super) {\n    __extends(ShuffleIterator, _super);\n    function ShuffleIterator(upstream, windowSize, seed) {\n        var _this = _super.call(this, upstream, windowSize) || this;\n        _this.upstream = upstream;\n        _this.windowSize = windowSize;\n        // Local state that should not be clobbered by out-of-order execution.\n        _this.upstreamExhausted = false;\n        _this.random = seedrandom.alea(seed || tf.util.now().toString());\n        _this.lastRead = Promise.resolve({ value: null, done: false });\n        return _this;\n    }\n    ShuffleIterator.prototype.next = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var _this = this;\n            return __generator(this, function (_a) {\n                // This sets this.lastRead to a new Promise right away, as opposed to\n                // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n                // would not work because this.nextRead would be updated only after the\n                // promise resolves.\n                this.lastRead = this.lastRead.then(function () { return _this.serialNext(); });\n                return [2 /*return*/, this.lastRead];\n            });\n        });\n    };\n    ShuffleIterator.prototype.randomInt = function (max) {\n        return Math.floor(this.random() * max);\n    };\n    ShuffleIterator.prototype.chooseIndex = function () {\n        return this.randomInt(this.buffer.length());\n    };\n    ShuffleIterator.prototype.serialNext = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var chosenIndex, result;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        // TODO(soergel): consider performance\n                        if (!this.upstreamExhausted) {\n                            this.refill();\n                        }\n                        _a.label = 1;\n                    case 1:\n                        if (!!this.buffer.isEmpty()) return [3 /*break*/, 3];\n                        chosenIndex = this.chooseIndex();\n                        return [4 /*yield*/, this.buffer.shuffleExcise(chosenIndex)];\n                    case 2:\n                        result = _a.sent();\n                        if (result.done) {\n                            this.upstreamExhausted = true;\n                        }\n                        else {\n                            this.refill();\n                            return [2 /*return*/, result];\n                        }\n                        return [3 /*break*/, 1];\n                    case 3: return [2 /*return*/, { value: null, done: true }];\n                }\n            });\n        });\n    };\n    return ShuffleIterator;\n}(PrefetchIterator));\nexports.ShuffleIterator = ShuffleIterator;\n//# sourceMappingURL=lazy_iterator.js.map","\"use strict\";\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tf = require(\"@tensorflow/tfjs-core\");\n/**\n * Apply a mapping function to a nested structure in a recursive manner.\n *\n * The result of the mapping is an object with the same nested structure (i.e.,\n * of arrays and dicts) as the input, except that some subtrees are replaced,\n * according to the results of the mapping function.\n *\n * Mappings are memoized.  Thus, if the nested structure contains the same\n * object in multiple positions, the output will contain the same mapped object\n * in those positions.  Cycles are not supported, however.\n *\n * @param input: The object to which to apply the mapping function.\n * @param mapFn: A function that expects a single node of the object tree, and\n *   returns a `DeepMapResult`.  The `DeepMapResult` either provides a\n *   replacement value for that node (i.e., replacing the subtree), or indicates\n *   that the node should be processed recursively.\n */\nfunction deepMap(input, mapFn) {\n    return deepMapInternal(input, mapFn);\n}\nexports.deepMap = deepMap;\n/**\n * @param seen: A Map of known object mappings (i.e., memoized results of\n *   `mapFn()`)\n * @param containedIn: An set containing objects on the reference path currently\n *   being processed (used to detect cycles).\n */\nfunction deepMapInternal(input, mapFn, seen, containedIn) {\n    if (seen === void 0) { seen = new Map(); }\n    if (containedIn === void 0) { containedIn = new Set(); }\n    if (input == null) {\n        return null;\n    }\n    if (containedIn.has(input)) {\n        throw new Error('Circular references are not supported.');\n    }\n    if (seen.has(input)) {\n        return seen.get(input);\n    }\n    var result = mapFn(input);\n    if (result.recurse && result.value !== null) {\n        throw new Error('A deep map function may not return both a value and recurse=true.');\n    }\n    if (!result.recurse) {\n        seen.set(input, result.value);\n        return result.value;\n    }\n    else if (isIterable(input)) {\n        // tslint:disable-next-line:no-any\n        var mappedIterable = Array.isArray(input) ? [] : {};\n        containedIn.add(input);\n        for (var k in input) {\n            var child = input[k];\n            var childResult = deepMapInternal(child, mapFn, seen, containedIn);\n            mappedIterable[k] = childResult;\n        }\n        containedIn.delete(input);\n        return mappedIterable;\n    }\n    else {\n        throw new Error(\"Can't recurse into non-iterable type: \" + input);\n    }\n}\n// TODO(soergel, kangyizhang) Reconsider naming of deepZip() to avoid confusion\n// with zip()\n/**\n * Zip nested structures together in a recursive manner.\n *\n * This has the effect of transposing or pivoting data, e.g. converting it from\n * a row-major representation to a column-major representation.\n *\n * For example, `deepZip([{a: 1, b: 2}, {a: 3, b: 4}])` returns\n * `{a: [1, 3], b: [2, 4]}`.\n *\n * The inputs should all have the same nested structure (i.e., of arrays and\n * dicts).  The result is a single object with the same nested structure, where\n * the leaves are arrays collecting the values of the inputs at that location\n * (or, optionally, the result of a custom function applied to those arrays).\n *\n * @param inputs: An array of the objects to zip together.\n * @param zipFn: (optional) A function that expects an array of elements at a\n *   single node of the object tree, and returns a `DeepMapResult`.  The\n *   `DeepMapResult` either provides a result value for that node (i.e.,\n *   representing the subtree), or indicates that the node should be processed\n *   recursively.  The default zipFn recurses as far as possible and places\n *   arrays at the leaves.\n */\nfunction deepZip(inputs, zipFn) {\n    if (zipFn === void 0) { zipFn = zipToList; }\n    return deepZipInternal(inputs, zipFn);\n}\nexports.deepZip = deepZip;\n/**\n * @param containedIn: An set containing objects on the reference path currently\n *   being processed (used to detect cycles).\n */\nfunction deepZipInternal(inputs, zipFn, containedIn) {\n    if (containedIn === void 0) { containedIn = new Set(); }\n    // The recursion follows the structure of input 0; it's assumed that all the\n    // other inputs have the same structure.\n    var input = inputs[0];\n    if (containedIn.has(input)) {\n        throw new Error('Circular references are not supported.');\n    }\n    var result = zipFn(inputs);\n    if (result.recurse && result.value !== null) {\n        throw new Error('A deep zip function may not return both a value and recurse=true.');\n    }\n    if (!result.recurse) {\n        return result.value;\n    }\n    else if (isIterable(input)) {\n        // tslint:disable-next-line:no-any\n        var mappedIterable = Array.isArray(input) ? [] : {};\n        containedIn.add(input);\n        var _loop_1 = function (k) {\n            var children = inputs.map(function (x) { return x[k]; });\n            var childResult = deepZipInternal(children, zipFn, containedIn);\n            mappedIterable[k] = childResult;\n        };\n        for (var k in input) {\n            _loop_1(k);\n        }\n        containedIn.delete(input);\n        return mappedIterable;\n    }\n    else {\n        throw new Error(\"Can't recurse into non-iterable type: \" + input);\n    }\n}\n// tslint:disable-next-line:no-any\nfunction zipToList(x) {\n    if (x === null) {\n        return null;\n    }\n    // TODO(soergel): validate array type?\n    if (isIterable(x[0])) {\n        return { value: null, recurse: true };\n    }\n    else {\n        return { value: x, recurse: false };\n    }\n}\nexports.zipToList = zipToList;\n/**\n * Apply an async mapping function to a nested structure in a recursive manner.\n *\n * This first creates a nested structure of Promises, and then awaits all of\n * those, resulting in a single Promise for a resolved nested structure.\n *\n * The result of the mapping is an object with the same nested structure (i.e.,\n * of arrays and dicts) as the input, except that some subtrees are replaced,\n * according to the results of the mapping function.\n *\n * Mappings are memoized.  Thus, if the nested structure contains the same\n * object in multiple positions, the output will contain the same mapped object\n * in those positions.  Cycles are not supported, however.\n *\n * @param input: The object to which to apply the mapping function.\n * @param mapFn: A function that expects a single node of the object tree, and\n *   returns a `DeepMapAsyncResult`.  The `DeepMapAsyncResult` either provides\n *   a `Promise` for a replacement value for that node (i.e., replacing the\n *   subtree), or indicates that the node should be processed recursively.  Note\n *   that the decision whether or not to recurse must be made immediately; only\n *   the mapped value may be promised.\n */\nfunction deepMapAndAwaitAll(input, mapFn) {\n    return __awaiter(this, void 0, void 0, function () {\n        var seen, _i, _a, key, value, mappedValue, result;\n        return __generator(this, function (_b) {\n            switch (_b.label) {\n                case 0:\n                    seen = new Map();\n                    // First do a normal deepMap, collecting Promises in 'seen' as a side effect.\n                    deepMapInternal(input, mapFn, seen);\n                    _i = 0, _a = Array.from(seen.keys());\n                    _b.label = 1;\n                case 1:\n                    if (!(_i < _a.length)) return [3 /*break*/, 4];\n                    key = _a[_i];\n                    value = seen.get(key);\n                    if (!(value instanceof Promise)) return [3 /*break*/, 3];\n                    return [4 /*yield*/, value];\n                case 2:\n                    mappedValue = _b.sent();\n                    seen.set(key, mappedValue);\n                    _b.label = 3;\n                case 3:\n                    _i++;\n                    return [3 /*break*/, 1];\n                case 4:\n                    result = deepMapInternal(input, mapFn, seen);\n                    return [2 /*return*/, result];\n            }\n        });\n    });\n}\nexports.deepMapAndAwaitAll = deepMapAndAwaitAll;\n/**\n * Determine whether the argument is iterable.\n *\n * @returns true if the argument is an array or any non-Tensor object.\n */\n// tslint:disable-next-line:no-any\nfunction isIterable(obj) {\n    return obj != null &&\n        (Array.isArray(obj) ||\n            (typeof obj === 'object' && !(obj instanceof tf.Tensor)));\n}\nexports.isIterable = isIterable;\n/**\n * Determine whether the argument can be converted to Tensor.\n *\n * Tensors, primitives, arrays, and TypedArrays all qualify; anything else does\n * not.\n *\n * @returns true if the argument can be converted to Tensor.\n */\n// tslint:disable-next-line:no-any\nfunction canTensorify(obj) {\n    return obj == null || isPrimitive(obj) || Array.isArray(obj) ||\n        (typeof obj === 'object' && (obj instanceof tf.Tensor)) ||\n        tf.util.isTypedArray(obj);\n}\nexports.canTensorify = canTensorify;\n/**\n * Returns true if the given `value` is a primitive type. Otherwise returns\n * false. This is equivalant to node util.isPrimitive\n */\nfunction isPrimitive(value) {\n    return ((typeof value !== 'object' && typeof value !== 'function') ||\n        value === null);\n}\n//# sourceMappingURL=deep_map.js.map","\"use strict\";\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar ring_buffer_1 = require(\"./ring_buffer\");\nvar GrowingRingBuffer = /** @class */ (function (_super) {\n    __extends(GrowingRingBuffer, _super);\n    /**\n     * Constructs a `GrowingRingBuffer`.\n     */\n    function GrowingRingBuffer() {\n        return _super.call(this, GrowingRingBuffer.INITIAL_CAPACITY) || this;\n    }\n    GrowingRingBuffer.prototype.isFull = function () {\n        return false;\n    };\n    GrowingRingBuffer.prototype.push = function (value) {\n        if (_super.prototype.isFull.call(this)) {\n            this.expand();\n        }\n        _super.prototype.push.call(this, value);\n    };\n    GrowingRingBuffer.prototype.unshift = function (value) {\n        if (_super.prototype.isFull.call(this)) {\n            this.expand();\n        }\n        _super.prototype.unshift.call(this, value);\n    };\n    /**\n     * Doubles the capacity of the buffer.\n     */\n    GrowingRingBuffer.prototype.expand = function () {\n        var newCapacity = this.capacity * 2;\n        var newData = new Array(newCapacity);\n        var len = this.length();\n        // Rotate the buffer to start at index 0 again, since we can't just\n        // allocate more space at the end.\n        for (var i = 0; i < len; i++) {\n            newData[i] = this.get(this.wrap(this.begin + i));\n        }\n        this.data = newData;\n        this.capacity = newCapacity;\n        this.doubledCapacity = 2 * this.capacity;\n        this.begin = 0;\n        this.end = len;\n    };\n    GrowingRingBuffer.INITIAL_CAPACITY = 32;\n    return GrowingRingBuffer;\n}(ring_buffer_1.RingBuffer));\nexports.GrowingRingBuffer = GrowingRingBuffer;\n//# sourceMappingURL=growing_ring_buffer.js.map","\"use strict\";\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * A ring buffer, providing O(1) FIFO, LIFO, and related operations.\n */\nvar RingBuffer = /** @class */ (function () {\n    /**\n     * Constructs a `RingBuffer`.\n     * @param capacity The number of items that the buffer can accomodate.\n     */\n    function RingBuffer(capacity) {\n        this.capacity = capacity;\n        // Note we store the indices in the range 0 <= index < 2*capacity.\n        // This allows us to distinguish the full from the empty case.\n        // See https://www.snellman.net/blog/archive/2016-12-13-ring-buffers/\n        this.begin = 0; // inclusive\n        this.end = 0; // exclusive\n        if (capacity == null) {\n            throw new RangeError('Can\\'t create a ring buffer of unknown capacity.');\n        }\n        if (capacity < 1) {\n            throw new RangeError('Can\\'t create ring buffer of capacity < 1.');\n        }\n        this.data = new Array(capacity);\n        this.doubledCapacity = 2 * capacity;\n    }\n    /**\n     * Map any index into the range 0 <= index < 2*capacity.\n     */\n    RingBuffer.prototype.wrap = function (index) {\n        // don't trust % on negative numbers\n        while (index < 0) {\n            index += this.doubledCapacity;\n        }\n        return index % this.doubledCapacity;\n    };\n    RingBuffer.prototype.get = function (index) {\n        if (index < 0) {\n            throw new RangeError('Can\\'t get item at a negative index.');\n        }\n        return this.data[index % this.capacity];\n    };\n    RingBuffer.prototype.set = function (index, value) {\n        if (index < 0) {\n            throw new RangeError('Can\\'t set item at a negative index.');\n        }\n        this.data[index % this.capacity] = value;\n    };\n    /**\n     * Returns the current number of items in the buffer.\n     */\n    RingBuffer.prototype.length = function () {\n        var length = this.end - this.begin;\n        if (length < 0) {\n            length = this.doubledCapacity + length;\n        }\n        return length;\n    };\n    /**\n     * Reports whether the buffer is full.\n     * @returns true if the number of items in the buffer equals its capacity, and\n     *   false otherwise.\n     */\n    RingBuffer.prototype.isFull = function () {\n        return this.length() === this.capacity;\n    };\n    /**\n     * Reports whether the buffer is empty.\n     * @returns true if the number of items in the buffer equals zero, and\n     *   false otherwise.\n     */\n    RingBuffer.prototype.isEmpty = function () {\n        return this.length() === 0;\n    };\n    /**\n     * Adds an item to the end of the buffer.\n     */\n    RingBuffer.prototype.push = function (value) {\n        if (this.isFull()) {\n            throw new RangeError('Ring buffer is full.');\n        }\n        this.set(this.end, value);\n        this.end = this.wrap(this.end + 1);\n    };\n    /**\n     * Adds many items to the end of the buffer, in order.\n     */\n    RingBuffer.prototype.pushAll = function (values) {\n        for (var _i = 0, values_1 = values; _i < values_1.length; _i++) {\n            var value = values_1[_i];\n            this.push(value);\n        }\n    };\n    /**\n     * Removes and returns the last item in the buffer.\n     */\n    RingBuffer.prototype.pop = function () {\n        if (this.isEmpty()) {\n            throw new RangeError('Ring buffer is empty.');\n        }\n        this.end = this.wrap(this.end - 1);\n        var result = this.get(this.end);\n        this.set(this.end, undefined);\n        return result;\n    };\n    /**\n     * Adds an item to the beginning of the buffer.\n     */\n    RingBuffer.prototype.unshift = function (value) {\n        if (this.isFull()) {\n            throw new RangeError('Ring buffer is full.');\n        }\n        this.begin = this.wrap(this.begin - 1);\n        this.set(this.begin, value);\n    };\n    /**\n     * Removes and returns the first item in the buffer.\n     */\n    RingBuffer.prototype.shift = function () {\n        if (this.isEmpty()) {\n            throw new RangeError('Ring buffer is empty.');\n        }\n        var result = this.get(this.begin);\n        this.set(this.begin, undefined);\n        this.begin = this.wrap(this.begin + 1);\n        return result;\n    };\n    /**\n     * Removes and returns a specific item in the buffer, and moves the last item\n     * to the vacated slot.  This is useful for implementing a shuffling stream.\n     * Note that this operation necessarily scrambles the original order.\n     *\n     * @param relativeIndex: the index of the item to remove, relative to the\n     *   first item in the buffer (e.g., hiding the ring nature of the underlying\n     *   storage).\n     */\n    RingBuffer.prototype.shuffleExcise = function (relativeIndex) {\n        if (this.isEmpty()) {\n            throw new RangeError('Ring buffer is empty.');\n        }\n        var index = this.wrap(this.begin + relativeIndex);\n        var result = this.get(index);\n        this.set(index, this.pop());\n        return result;\n    };\n    return RingBuffer;\n}());\nexports.RingBuffer = RingBuffer;\n//# sourceMappingURL=ring_buffer.js.map","\"use strict\";\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tfjs_core_1 = require(\"@tensorflow/tfjs-core\");\nvar dataset_1 = require(\"../dataset\");\nvar text_line_dataset_1 = require(\"./text_line_dataset\");\nvar CODE_QUOTE = '\"';\nvar STATE_OUT = Symbol('out');\nvar STATE_FIELD = Symbol('field');\nvar STATE_QUOTE = Symbol('quote');\nvar STATE_QUOTE_AFTER_QUOTE = Symbol('quoteafterquote');\nvar STATE_WITHIN_QUOTE_IN_QUOTE = Symbol('quoteinquote');\n/**\n * Represents a potentially large collection of delimited text records.\n *\n * The produced `DataElement`s each contain one key-value pair for\n * every column of the table.  When a field is empty in the incoming data, the\n * resulting value is `undefined`, or throw error if it is required.  Values\n * that can be parsed as numbers are emitted as type `number`, other values\n * are parsed as `string`.\n *\n * The results are not batched.\n */\n/** @doc {heading: 'Data', subheading: 'Classes', namespace: 'data'} */\nvar CSVDataset = /** @class */ (function (_super) {\n    __extends(CSVDataset, _super);\n    /**\n     * Create a `CSVDataset`.\n     *\n     * @param input A `DataSource` providing a chunked, UTF8-encoded byte stream.\n     * @param csvConfig (Optional) A CSVConfig object that contains configurations\n     *     of reading and decoding from CSV file(s).\n     *\n     *     hasHeader: (Optional) A boolean value that indicates whether the first\n     *     row of provided CSV file is a header line with column names, and should\n     *     not be included in the data. Defaults to `true`.\n     *\n     *     columnNames: (Optional) A list of strings that corresponds to\n     *     the CSV column names, in order. If provided, it ignores the column\n     *     names inferred from the header row. If not provided, infers the column\n     *     names from the first row of the records. If hasHeader is false and\n     *     columnNames is not provided, this method throws an error.\n     *\n     *     columnConfigs: (Optional) A dictionary whose key is column names, value\n     *     is an object stating if this column is required, column's data type,\n     *     default value, and if this column is label. If provided, keys must\n     *     correspond to names provided in columnNames or inferred from the file\n     *     header lines. If isLabel is true any column, returns an array of two\n     *     items: the first item is a dict of features key/value pairs, the second\n     *     item is a dict of labels key/value pairs. If no feature is marked as\n     *     label, returns a dict of features only.\n     *\n     *     configuredColumnsOnly (Optional) If true, only columns provided in\n     *     columnConfigs will be parsed and provided during iteration.\n     *\n     *     delimiter (Optional) The string used to parse each line of the input\n     *     file. Defaults to `,`.\n     */\n    function CSVDataset(input, csvConfig) {\n        var _this = _super.call(this) || this;\n        _this.input = input;\n        _this.hasHeader = true;\n        _this.fullColumnNames = null;\n        _this.columnNamesValidated = false;\n        _this.columnConfigs = null;\n        _this.configuredColumnsOnly = false;\n        _this.delimiter = ',';\n        _this.base = new text_line_dataset_1.TextLineDataset(input);\n        if (!csvConfig) {\n            csvConfig = {};\n        }\n        _this.hasHeader = csvConfig.hasHeader === false ? false : true;\n        _this.fullColumnNames = csvConfig.columnNames;\n        _this.columnConfigs = csvConfig.columnConfigs;\n        _this.configuredColumnsOnly = csvConfig.configuredColumnsOnly;\n        _this.delimiter = csvConfig.delimiter ? csvConfig.delimiter : ',';\n        return _this;\n    }\n    /**\n     * Returns column names of the csv dataset. If `configuredColumnsOnly` is\n     * true, return column names in `columnConfigs`. If `configuredColumnsOnly` is\n     * false and `columnNames` is provided, `columnNames`. If\n     * `configuredColumnsOnly` is false and `columnNames` is not provided, return\n     * all column names parsed from the csv file. For example usage please go to\n     * `tf.data.csv`.\n     */\n    /** @doc {heading: 'Data', subheading: 'Classes'} */\n    CSVDataset.prototype.columnNames = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        if (!!this.columnNamesValidated) return [3 /*break*/, 2];\n                        return [4 /*yield*/, this.setColumnNames()];\n                    case 1:\n                        _a.sent();\n                        _a.label = 2;\n                    case 2: return [2 /*return*/, this.configuredColumnsOnly ? Object.keys(this.columnConfigs) :\n                            this.fullColumnNames];\n                }\n            });\n        });\n    };\n    /* 1) If `columnNames` is provided as string[], use this string[] as output\n     * keys in corresponding order. The length must match the number of inferred\n     * columns if `hasHeader` is true .\n     * 2) If `columnNames` is not provided, parse header line as `columnNames` if\n     * hasHeader is true. If `hasHeader` is false, throw an error.\n     * 3) If `columnConfigs` is provided, all the keys in `columnConfigs` must\n     * exist in parsed `columnNames`.\n     */\n    CSVDataset.prototype.setColumnNames = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var columnNamesFromFile, counts, duplicateNames, _i, _a, key, index;\n            var _this = this;\n            return __generator(this, function (_b) {\n                switch (_b.label) {\n                    case 0: return [4 /*yield*/, this.maybeReadHeaderLine()];\n                    case 1:\n                        columnNamesFromFile = _b.sent();\n                        if (!this.fullColumnNames && !columnNamesFromFile) {\n                            // Throw an error if columnNames is not provided and no header line.\n                            throw new Error('Column names must be provided if there is no header line.');\n                        }\n                        else if (this.fullColumnNames && columnNamesFromFile) {\n                            // Check provided columnNames match header line.\n                            tfjs_core_1.util.assert(columnNamesFromFile.length === this.fullColumnNames.length, function () { return 'The length of provided columnNames (' +\n                                _this.fullColumnNames.length.toString() +\n                                ') does not match the length of the header line read from ' +\n                                'file (' + columnNamesFromFile.length.toString() + ').'; });\n                        }\n                        if (!this.fullColumnNames) {\n                            this.fullColumnNames = columnNamesFromFile;\n                        }\n                        counts = this.fullColumnNames.reduce(function (countAcc, name) {\n                            countAcc[name] = (countAcc[name] + 1) || 1;\n                            return countAcc;\n                        }, {});\n                        duplicateNames = Object.keys(counts).filter(function (name) { return (counts[name] > 1); });\n                        tfjs_core_1.util.assert(duplicateNames.length === 0, function () { return 'Duplicate column names found: ' + duplicateNames.toString(); });\n                        // Check if keys in columnConfigs match columnNames.\n                        if (this.columnConfigs) {\n                            for (_i = 0, _a = Object.keys(this.columnConfigs); _i < _a.length; _i++) {\n                                key = _a[_i];\n                                index = this.fullColumnNames.indexOf(key);\n                                if (index === -1) {\n                                    throw new Error('The key \"' + key +\n                                        '\" provided in columnConfigs does not match any of the column ' +\n                                        'names (' + this.fullColumnNames.toString() + ').');\n                                }\n                            }\n                        }\n                        this.columnNamesValidated = true;\n                        return [2 /*return*/];\n                }\n            });\n        });\n    };\n    CSVDataset.prototype.maybeReadHeaderLine = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var iter, firstElement, firstLine;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        if (!this.hasHeader) return [3 /*break*/, 3];\n                        return [4 /*yield*/, this.base.iterator()];\n                    case 1:\n                        iter = _a.sent();\n                        return [4 /*yield*/, iter.next()];\n                    case 2:\n                        firstElement = _a.sent();\n                        if (firstElement.done) {\n                            throw new Error('No data was found for CSV parsing.');\n                        }\n                        firstLine = firstElement.value;\n                        return [2 /*return*/, firstLine.split(this.delimiter)];\n                    case 3: return [2 /*return*/, null];\n                }\n            });\n        });\n    };\n    CSVDataset.prototype.iterator = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var lines;\n            var _this = this;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        if (!!this.columnNamesValidated) return [3 /*break*/, 2];\n                        return [4 /*yield*/, this.setColumnNames()];\n                    case 1:\n                        _a.sent();\n                        _a.label = 2;\n                    case 2: return [4 /*yield*/, this.base.iterator()];\n                    case 3:\n                        lines = _a.sent();\n                        if (this.hasHeader) {\n                            // We previously read the first line to get the columnNames.\n                            // Now that we're providing data, skip it.\n                            lines = lines.skip(1);\n                        }\n                        return [2 /*return*/, lines.map(function (x) { return _this.makeDataElement(x); })];\n                }\n            });\n        });\n    };\n    CSVDataset.prototype.makeDataElement = function (line) {\n        var values = this.parseRow(line);\n        var features = {};\n        var labels = {};\n        for (var i = 0; i < this.fullColumnNames.length; i++) {\n            var key = this.fullColumnNames[i];\n            var config = this.columnConfigs ? this.columnConfigs[key] : null;\n            if (this.configuredColumnsOnly && !config) {\n                // This column is not selected.\n                continue;\n            }\n            else {\n                var value = values[i];\n                var parsedValue = null;\n                if (value === '') {\n                    // If default value is provided, use it. If default value is not\n                    // provided, set as undefined.\n                    if (config && config.default !== undefined) {\n                        parsedValue = config.default;\n                    }\n                    else if (config && (config.required || config.isLabel)) {\n                        throw new Error(\"Required column \" + key + \" is empty in this line: \" + line);\n                    }\n                    else {\n                        parsedValue = undefined;\n                    }\n                }\n                else {\n                    // A value is present, so parse it based on type\n                    var valueAsNum = Number(value);\n                    if (isNaN(valueAsNum)) {\n                        // The value is a string and this column is declared as boolean\n                        // in config, parse it as boolean.\n                        if (config && config.dtype === 'bool') {\n                            parsedValue = this.getBoolean(value);\n                        }\n                        else {\n                            // Set value as string\n                            parsedValue = value;\n                        }\n                    }\n                    else if (!config || !config.dtype) {\n                        // If this value is a number and no type config is provided, return\n                        // it as number.\n                        parsedValue = valueAsNum;\n                    }\n                    else {\n                        // If this value is a number and data type is provided, parse it\n                        // according to provided data type.\n                        switch (config.dtype) {\n                            case 'float32':\n                                parsedValue = valueAsNum;\n                                break;\n                            case 'int32':\n                                parsedValue = Math.floor(valueAsNum);\n                                break;\n                            case 'bool':\n                                parsedValue = this.getBoolean(value);\n                                break;\n                            default:\n                                parsedValue = valueAsNum;\n                        }\n                    }\n                }\n                // Check if this column is label.\n                (config && config.isLabel) ? labels[key] = parsedValue :\n                    features[key] = parsedValue;\n            }\n        }\n        // If label exists, return an object of features and labels as {xs:features,\n        // ys:labels}, otherwise return features only.\n        if (Object.keys(labels).length === 0) {\n            return features;\n        }\n        else {\n            return { xs: features, ys: labels };\n        }\n    };\n    CSVDataset.prototype.getBoolean = function (value) {\n        if (value === '1' || value.toLowerCase() === 'true') {\n            return 1;\n        }\n        else {\n            return 0;\n        }\n    };\n    // adapted from https://beta.observablehq.com/@mbostock/streaming-csv\n    CSVDataset.prototype.parseRow = function (line) {\n        var result = [];\n        var readOffset = 0;\n        var readLength = line.length;\n        var currentState = STATE_FIELD;\n        // Goes through the line to parse quote.\n        for (var i = 0; i < readLength; i++) {\n            switch (currentState) {\n                // Before enter a new field\n                case STATE_OUT:\n                    switch (line.charAt(i)) {\n                        // Enter a quoted field\n                        case CODE_QUOTE:\n                            readOffset = i + 1;\n                            currentState = STATE_QUOTE;\n                            break;\n                        // Read an empty field\n                        case this.delimiter:\n                            result.push('');\n                            currentState = STATE_OUT;\n                            readOffset = i + 1;\n                            break;\n                        // Enter an unquoted field\n                        default:\n                            currentState = STATE_FIELD;\n                            readOffset = i;\n                            break;\n                    }\n                    break;\n                // In an unquoted field\n                case STATE_FIELD:\n                    switch (line.charAt(i)) {\n                        // Exit an unquoted field, add it to result\n                        case this.delimiter:\n                            result.push(line.substring(readOffset, i));\n                            currentState = STATE_OUT;\n                            readOffset = i + 1;\n                            break;\n                        default:\n                    }\n                    break;\n                // In a quoted field\n                case STATE_QUOTE:\n                    switch (line.charAt(i)) {\n                        // Read a quote after a quote\n                        case CODE_QUOTE:\n                            currentState = STATE_QUOTE_AFTER_QUOTE;\n                            break;\n                        default:\n                    }\n                    break;\n                // This state means it's right after a second quote in a field\n                case STATE_QUOTE_AFTER_QUOTE:\n                    switch (line.charAt(i)) {\n                        // Finished a quoted field\n                        case this.delimiter:\n                            result.push(line.substring(readOffset, i - 1));\n                            currentState = STATE_OUT;\n                            readOffset = i + 1;\n                            break;\n                        // Finished a quoted part in a quoted field\n                        case CODE_QUOTE:\n                            currentState = STATE_QUOTE;\n                            break;\n                        // In a quoted part in a quoted field\n                        default:\n                            currentState = STATE_WITHIN_QUOTE_IN_QUOTE;\n                            break;\n                    }\n                    break;\n                case STATE_WITHIN_QUOTE_IN_QUOTE:\n                    switch (line.charAt(i)) {\n                        // Exit a quoted part in a quoted field\n                        case CODE_QUOTE:\n                            currentState = STATE_QUOTE;\n                            break;\n                        default:\n                    }\n                    break;\n                default:\n            }\n        }\n        // Adds last item based on if it is quoted.\n        if (currentState === STATE_QUOTE_AFTER_QUOTE) {\n            result.push(line.substring(readOffset, readLength - 1));\n        }\n        else {\n            result.push(line.substring(readOffset));\n        }\n        return result;\n    };\n    return CSVDataset;\n}(dataset_1.Dataset));\nexports.CSVDataset = CSVDataset;\n// TODO(soergel): add more basic datasets for parity with tf.data\n// tf.data.FixedLengthRecordDataset()\n// tf.data.TFRecordDataset()\n//# sourceMappingURL=csv_dataset.js.map","\"use strict\";\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar dataset_1 = require(\"../dataset\");\n/**\n * Represents a potentially large collection of text lines.\n *\n * The results are not batched.\n */\nvar TextLineDataset = /** @class */ (function (_super) {\n    __extends(TextLineDataset, _super);\n    /**\n     * Create a `TextLineDataset`.\n     *\n     * @param input A `DataSource` providing a chunked, UTF8-encoded byte stream.\n     */\n    function TextLineDataset(input) {\n        var _this = _super.call(this) || this;\n        _this.input = input;\n        return _this;\n    }\n    TextLineDataset.prototype.iterator = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var inputIterator, utf8Iterator, lineIterator;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0: return [4 /*yield*/, this.input.iterator()];\n                    case 1:\n                        inputIterator = _a.sent();\n                        utf8Iterator = inputIterator.decodeUTF8();\n                        lineIterator = utf8Iterator.split('\\n');\n                        return [2 /*return*/, lineIterator];\n                }\n            });\n        });\n    };\n    return TextLineDataset;\n}(dataset_1.Dataset));\nexports.TextLineDataset = TextLineDataset;\n//# sourceMappingURL=text_line_dataset.js.map","\"use strict\";\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar dataset_1 = require(\"./dataset\");\nvar csv_dataset_1 = require(\"./datasets/csv_dataset\");\nvar lazy_iterator_1 = require(\"./iterators/lazy_iterator\");\nvar url_data_source_1 = require(\"./sources/url_data_source\");\n/**\n * Create a `CSVDataset` by reading and decoding CSV file(s) from provided URL\n * or local path if it's in Node environment.\n *\n * Note: If isLabel in columnConfigs is `true` for at least one column, the\n * element in returned `CSVDataset` will be an object of\n * `{xs:features, ys:labels}`: xs is a dict of features key/value pairs, ys\n * is a dict of labels key/value pairs. If no column is marked as label,\n * returns a dict of features only.\n *\n * ```js\n * const csvUrl =\n * 'https://storage.googleapis.com/tfjs-examples/multivariate-linear-regression/data/boston-housing-train.csv';\n *\n * async function run() {\n *   // We want to predict the column \"medv\", which represents a median value of\n *   // a home (in $1000s), so we mark it as a label.\n *   const csvDataset = tf.data.csv(\n *     csvUrl, {\n *       columnConfigs: {\n *         medv: {\n *           isLabel: true\n *         }\n *       }\n *     });\n *\n *   // Number of features is the number of column names minus one for the label\n *   // column.\n *   const numOfFeatures = (await csvDataset.columnNames()).length - 1;\n *\n *   // Prepare the Dataset for training.\n *   const flattenedDataset =\n *     csvDataset\n *     .map(({xs, ys}) =>\n *       {\n *         // Convert xs(features) and ys(labels) from object form (keyed by\n *         // column name) to array form.\n *         return {xs:Object.values(xs), ys:Object.values(ys)};\n *       })\n *     .batch(10);\n *\n *   // Define the model.\n *   const model = tf.sequential();\n *   model.add(tf.layers.dense({\n *     inputShape: [numOfFeatures],\n *     units: 1\n *   }));\n *   model.compile({\n *     optimizer: tf.train.sgd(0.000001),\n *     loss: 'meanSquaredError'\n *   });\n *\n *   // Fit the model using the prepared Dataset\n *   return model.fitDataset(flattenedDataset, {\n *     epochs: 10,\n *     callbacks: {\n *       onEpochEnd: async (epoch, logs) => {\n *         console.log(epoch + ':' + logs.loss);\n *       }\n *     }\n *   });\n * }\n *\n * await run();\n * ```\n *\n * @param source URL or local path to get CSV file. If it's a local path, it\n * must have prefix `file://` and it only works in node environment.\n * @param csvConfig (Optional) A CSVConfig object that contains configurations\n *     of reading and decoding from CSV file(s).\n */\n/**\n * @doc {\n *   heading: 'Data',\n *   subheading: 'Creation',\n *   namespace: 'data',\n *   configParamIndices: [1]\n *  }\n */\nfunction csv(source, csvConfig) {\n    if (csvConfig === void 0) { csvConfig = {}; }\n    return new csv_dataset_1.CSVDataset(new url_data_source_1.URLDataSource(source), csvConfig);\n}\nexports.csv = csv;\n/**\n * Create a `Dataset` that produces each element by calling a provided function.\n *\n * Note that repeated iterations over this `Dataset` may produce different\n * results, because the function will be called anew for each element of each\n * iteration.\n *\n * Also, beware that the sequence of calls to this function may be out of order\n * in time with respect to the logical order of the Dataset. This is due to the\n * asynchronous lazy nature of stream processing, and depends on downstream\n * transformations (e.g. .shuffle()). If the provided function is pure, this is\n * no problem, but if it is a closure over a mutable state (e.g., a traversal\n * pointer), then the order of the produced elements may be scrambled.\n *\n * ```js\n * let i = -1;\n * const func = () =>\n *    ++i < 5 ? {value: i, done: false} : {value: null, done: true};\n * const ds = tf.data.func(func);\n * await ds.forEachAsync(e => console.log(e));\n * ```\n *\n * @param f A function that produces one data element on each call.\n */\nfunction func(f) {\n    var _this = this;\n    var iter = lazy_iterator_1.iteratorFromFunction(f);\n    return dataset_1.datasetFromIteratorFn(function () { return __awaiter(_this, void 0, void 0, function () { return __generator(this, function (_a) {\n        return [2 /*return*/, iter];\n    }); }); });\n}\nexports.func = func;\n/**\n * Create a `Dataset` that produces each element from provided JavaScript\n * generator, which is a function*\n * (https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Iterators_and_Generators#Generator_functions),\n * or a function that returns an\n * iterator\n * (https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Iterators_and_Generators#Generator_functions).\n *\n * The returned iterator should have `.next()` function that returns element in\n * format of `{value: DataElement, done:boolean}`.\n *\n * Example of creating a dataset from an iterator factory:\n * ```js\n * function makeIterator() {\n *   const numElements = 10;\n *   let index = 0;\n *\n *   const iterator = {\n *     next: () => {\n *       let result;\n *       if (index < numElements) {\n *         result = {value: index, done: false};\n *         index++;\n *         return result;\n *       }\n *       return {value: index, done: true};\n *     }\n *   };\n *   return iterator;\n * }\n * const ds = tf.data.generator(makeIterator);\n * ds.forEachAsync(e => console.log(e));\n * ```\n *\n * Example of creating a dataset from a generator:\n * ```js\n * function* dataGenerator() {\n *   const numElements = 10;\n *   let index = 0;\n *   while (index < numElements) {\n *     const x = index;\n *     index++;\n *     yield x;\n *   }\n * }\n *\n * const ds = tf.data.generator(dataGenerator);\n * ds.forEachAsync(e => console.log(e));\n * ```\n *\n * @param generator A Javascript generator function that returns a JavaScript\n *     iterator.\n */\n/**\n * @doc {\n *   heading: 'Data',\n *   subheading: 'Creation',\n *   namespace: 'data',\n *   configParamIndices: [1]\n *  }\n */\nfunction generator(generator) {\n    var _this = this;\n    return dataset_1.datasetFromIteratorFn(function () { return __awaiter(_this, void 0, void 0, function () {\n        var gen;\n        return __generator(this, function (_a) {\n            switch (_a.label) {\n                case 0: return [4 /*yield*/, generator()];\n                case 1:\n                    gen = _a.sent();\n                    return [2 /*return*/, lazy_iterator_1.iteratorFromFunction(function () { return gen.next(); })];\n            }\n        });\n    }); });\n}\nexports.generator = generator;\n//# sourceMappingURL=readers.js.map","\"use strict\";\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar datasource_1 = require(\"../datasource\");\nvar url_chunk_iterator_1 = require(\"../iterators/url_chunk_iterator\");\nvar source_util_1 = require(\"../util/source_util\");\nvar file_data_source_1 = require(\"./file_data_source\");\n/*\n * Represents a URL readable as a stream of binary data chunks.\n */\nvar URLDataSource = /** @class */ (function (_super) {\n    __extends(URLDataSource, _super);\n    /**\n     * Create a `URLDataSource`.\n     *\n     * @param url A source URL string, or a `Request` object.\n     * @param options Options passed to the underlying `FileChunkIterator`s,\n     *   such as {chunksize: 1024}.\n     */\n    function URLDataSource(url, fileOptions) {\n        if (fileOptions === void 0) { fileOptions = {}; }\n        var _this = _super.call(this) || this;\n        _this.url = url;\n        _this.fileOptions = fileOptions;\n        return _this;\n    }\n    // TODO(soergel): provide appropriate caching options.  Currently this\n    // will download the URL anew for each call to iterator().  Since we have\n    // to treat the downloaded file as a blob/buffer anyway, we may as well retain\n    // it-- but that raises GC issues.  Also we may want a persistent disk cache.\n    URLDataSource.prototype.iterator = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                if (source_util_1.isLocalPath(this.url)) {\n                    return [2 /*return*/, (new file_data_source_1.FileDataSource(this.url, this.fileOptions))\n                            .iterator()];\n                }\n                else {\n                    return [2 /*return*/, url_chunk_iterator_1.urlChunkIterator(this.url, this.fileOptions)];\n                }\n                return [2 /*return*/];\n            });\n        });\n    };\n    return URLDataSource;\n}(datasource_1.DataSource));\nexports.URLDataSource = URLDataSource;\n//# sourceMappingURL=url_data_source.js.map","\"use strict\";\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * Represents a data source readable as a stream of binary data chunks.\n *\n * Because `Dataset`s can be read repeatedly (via `Dataset.iterator()`), this\n * provides a means to repeatedly create streams from the underlying data\n * sources.\n */\nvar DataSource = /** @class */ (function () {\n    function DataSource() {\n    }\n    return DataSource;\n}());\nexports.DataSource = DataSource;\n// TODO(soergel): consider convenience factory functions here\n// in combination with chainable source->dataset above, e.g.:\n// tf.data.url(...).asCsvDataset().shuffle().batch()\n//# sourceMappingURL=datasource.js.map","\"use strict\";\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tfjs_core_1 = require(\"@tensorflow/tfjs-core\");\nvar file_chunk_iterator_1 = require(\"./file_chunk_iterator\");\n/**\n * Provide a stream of chunks from a URL.\n *\n * Note this class first downloads the entire file into memory before providing\n * the first element from the stream.  This is because the Fetch API does not\n * yet reliably provide a reader stream for the response body.\n */\nfunction urlChunkIterator(url, options) {\n    if (options === void 0) { options = {}; }\n    return __awaiter(this, void 0, void 0, function () {\n        var response, blob, nodeFetch, unitArray;\n        return __generator(this, function (_a) {\n            switch (_a.label) {\n                case 0:\n                    if (!tfjs_core_1.ENV.get('IS_BROWSER')) return [3 /*break*/, 5];\n                    return [4 /*yield*/, fetch(url)];\n                case 1:\n                    response = _a.sent();\n                    if (!response.ok) return [3 /*break*/, 3];\n                    return [4 /*yield*/, response.blob()];\n                case 2:\n                    blob = _a.sent();\n                    return [2 /*return*/, new file_chunk_iterator_1.FileChunkIterator(blob, options)];\n                case 3: throw new Error(response.statusText);\n                case 4: return [3 /*break*/, 9];\n                case 5:\n                    nodeFetch = require('node-fetch');\n                    if (typeof url !== 'string') {\n                        throw new Error('URL must be a string. Request objects are not supported ' +\n                            'in the node.js environment yet.');\n                    }\n                    return [4 /*yield*/, nodeFetch(url)];\n                case 6:\n                    response = _a.sent();\n                    if (!response.ok) return [3 /*break*/, 8];\n                    return [4 /*yield*/, response.buffer()];\n                case 7:\n                    unitArray = _a.sent();\n                    return [2 /*return*/, new file_chunk_iterator_1.FileChunkIterator(unitArray, options)];\n                case 8: throw new Error(response.statusText);\n                case 9: return [2 /*return*/];\n            }\n        });\n    });\n}\nexports.urlChunkIterator = urlChunkIterator;\n//# sourceMappingURL=url_chunk_iterator.js.map","\"use strict\";\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\n// inspired by https://github.com/maxogden/filereader-stream\nvar tfjs_core_1 = require(\"@tensorflow/tfjs-core\");\nvar byte_chunk_iterator_1 = require(\"./byte_chunk_iterator\");\n/**\n * Provide a stream of chunks from a File, Blob, or Uint8Array.\n * @param file The source File, Blob or Uint8Array.\n * @param options Optional settings controlling file reading.\n * @returns a lazy Iterator of Uint8Arrays containing sequential chunks of the\n *   input File, Blob or Uint8Array.\n */\nvar FileChunkIterator = /** @class */ (function (_super) {\n    __extends(FileChunkIterator, _super);\n    function FileChunkIterator(file, options) {\n        if (options === void 0) { options = {}; }\n        var _this = _super.call(this) || this;\n        _this.file = file;\n        _this.options = options;\n        tfjs_core_1.util.assert((file instanceof Uint8Array) ||\n            (tfjs_core_1.ENV.get('IS_BROWSER') ?\n                (file instanceof File || file instanceof Blob) :\n                false), function () { return 'FileChunkIterator only supports File, Blob and Uint8Array ' +\n            'right now.'; });\n        _this.offset = options.offset || 0;\n        // default 1MB chunk has tolerable perf on large files\n        _this.chunkSize = options.chunkSize || 1024 * 1024;\n        return _this;\n    }\n    FileChunkIterator.prototype.summary = function () {\n        return \"FileChunks \" + this.file;\n    };\n    FileChunkIterator.prototype.next = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var chunk, _a;\n            var _this = this;\n            return __generator(this, function (_b) {\n                switch (_b.label) {\n                    case 0:\n                        if (this.offset >= ((this.file instanceof Uint8Array) ?\n                            this.file.byteLength :\n                            this.file.size)) {\n                            return [2 /*return*/, { value: null, done: true }];\n                        }\n                        chunk = new Promise(function (resolve, reject) {\n                            var end = _this.offset + _this.chunkSize;\n                            if (_this.file instanceof Uint8Array) {\n                                // Note if end > this.uint8Array.byteLength, we just get a small last\n                                // chunk.\n                                resolve(new Uint8Array(_this.file.slice(_this.offset, end)));\n                            }\n                            else {\n                                // This branch assumes that this.file type is File or Blob, which\n                                // means it is in the browser environment.\n                                // TODO(soergel): is this a performance issue?\n                                var fileReader_1 = new FileReader();\n                                fileReader_1.onload = function (event) {\n                                    var data = fileReader_1.result;\n                                    // Not sure we can trust the return type of\n                                    // FileReader.readAsArrayBuffer See e.g.\n                                    // https://github.com/node-file-api/FileReader/issues/2\n                                    if (data instanceof ArrayBuffer) {\n                                        data = new Uint8Array(data);\n                                    }\n                                    if (!(data instanceof Uint8Array)) {\n                                        return reject(new TypeError('FileReader returned unknown type.'));\n                                    }\n                                    resolve(data);\n                                };\n                                fileReader_1.onabort = function (event) {\n                                    return reject(new Error('Aborted'));\n                                };\n                                fileReader_1.onerror = function (event) {\n                                    return reject(new Error(event.type));\n                                };\n                                // TODO(soergel): better handle onabort, onerror\n                                // Note if end > this.file.size, we just get a small last chunk.\n                                var slice = _this.file.slice(_this.offset, end);\n                                // We can't use readAsText here (even if we know the file is text)\n                                // because the slice boundary may fall within a multi-byte character.\n                                fileReader_1.readAsArrayBuffer(slice);\n                            }\n                            _this.offset = end;\n                        });\n                        _a = {};\n                        return [4 /*yield*/, chunk];\n                    case 1: return [2 /*return*/, (_a.value = (_b.sent()), _a.done = false, _a)];\n                }\n            });\n        });\n    };\n    return FileChunkIterator;\n}(byte_chunk_iterator_1.ByteChunkIterator));\nexports.FileChunkIterator = FileChunkIterator;\n//# sourceMappingURL=file_chunk_iterator.js.map","\"use strict\";\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tfjs_core_1 = require(\"@tensorflow/tfjs-core\");\nvar lazy_iterator_1 = require(\"./lazy_iterator\");\nvar string_iterator_1 = require(\"./string_iterator\");\nvar ByteChunkIterator = /** @class */ (function (_super) {\n    __extends(ByteChunkIterator, _super);\n    function ByteChunkIterator() {\n        return _super !== null && _super.apply(this, arguments) || this;\n    }\n    /**\n     * Decode a stream of UTF8-encoded byte arrays to a stream of strings.\n     *\n     * The byte arrays producetd from the ByteChunkIterator on which this is\n     * called will be interpreted as concatenated.  No assumptions are made about\n     * the boundaries of the incoming chunks, so a multi-byte UTF8 encoding of a\n     * character may span the boundary between chunks.  This naturally happens,\n     * for instance, when reading fixed-size byte arrays from a file.\n     */\n    ByteChunkIterator.prototype.decodeUTF8 = function () {\n        return new Utf8Iterator(this);\n    };\n    return ByteChunkIterator;\n}(lazy_iterator_1.LazyIterator));\nexports.ByteChunkIterator = ByteChunkIterator;\n// ============================================================================\n// The following private classes serve to implement the chainable methods\n// on ByteChunkIterator.  Unfortunately they can't be placed in separate files,\n// due to resulting trouble with circular imports.\n// ============================================================================\n// We wanted multiple inheritance, e.g.\n//   class Utf8Iterator extends QueueIterator<string>, StringIterator\n// but the TypeScript mixin approach is a bit hacky, so we take this adapter\n// approach instead.\nvar Utf8Iterator = /** @class */ (function (_super) {\n    __extends(Utf8Iterator, _super);\n    function Utf8Iterator(upstream) {\n        var _this = _super.call(this) || this;\n        _this.upstream = upstream;\n        _this.impl = new Utf8IteratorImpl(upstream);\n        return _this;\n    }\n    Utf8Iterator.prototype.summary = function () {\n        return this.impl.summary();\n    };\n    Utf8Iterator.prototype.next = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                return [2 /*return*/, this.impl.next()];\n            });\n        });\n    };\n    return Utf8Iterator;\n}(string_iterator_1.StringIterator));\n/**\n * Decode a stream of UTF8-encoded byte arrays to a stream of strings.\n *\n * This is tricky because the incoming byte array boundaries may disrupt a\n * multi-byte UTF8 character. Thus any incomplete character data at the end of\n * a chunk must be carried over and prepended to the next chunk before\n * decoding. Luckily with native decoder, TextDecoder in browser and\n * string_decoder in node, byte array boundaries are handled automatically.\n *\n * In the context of an input pipeline for machine learning, UTF8 decoding is\n * needed to parse text files containing training examples or prediction\n * requests (e.g., formatted as CSV or JSON). We cannot use the built-in\n * decoding provided by FileReader.readAsText() because here we are in a\n * streaming context, which FileReader does not support.\n *\n * @param upstream A `LazyIterator` of `Uint8Arrays` containing UTF8-encoded\n *   text, which should be interpreted as concatenated.  No assumptions are\n *   made about the boundaries of the incoming chunks, so a multi-byte UTF8\n *   encoding of a character may span the boundary between chunks.  This\n *   naturally happens, for instance, when reading fixed-size byte arrays from a\n *   file.\n */\nvar Utf8IteratorImpl = /** @class */ (function (_super) {\n    __extends(Utf8IteratorImpl, _super);\n    function Utf8IteratorImpl(upstream) {\n        var _this = _super.call(this) || this;\n        _this.upstream = upstream;\n        if (tfjs_core_1.ENV.get('IS_BROWSER')) {\n            _this.decoder = new TextDecoder('utf-8');\n        }\n        else {\n            // tslint:disable-next-line:no-require-imports\n            var StringDecoder = require('string_decoder').StringDecoder;\n            _this.decoder = new StringDecoder('utf8');\n        }\n        return _this;\n    }\n    Utf8IteratorImpl.prototype.summary = function () {\n        return this.upstream.summary() + \" -> Utf8\";\n    };\n    Utf8IteratorImpl.prototype.pump = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var chunkResult, chunk, text;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0: return [4 /*yield*/, this.upstream.next()];\n                    case 1:\n                        chunkResult = _a.sent();\n                        if (chunkResult.done) {\n                            return [2 /*return*/, false];\n                        }\n                        else {\n                            chunk = chunkResult.value;\n                        }\n                        if (tfjs_core_1.ENV.get('IS_BROWSER')) {\n                            text = this.decoder.decode(chunk, { stream: true });\n                        }\n                        else {\n                            text = this.decoder.write(Buffer.from(chunk.buffer));\n                        }\n                        this.outputQueue.push(text);\n                        return [2 /*return*/, true];\n                }\n            });\n        });\n    };\n    return Utf8IteratorImpl;\n}(lazy_iterator_1.OneToManyIterator));\n//# sourceMappingURL=byte_chunk_iterator.js.map","\"use strict\";\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar lazy_iterator_1 = require(\"./lazy_iterator\");\nvar StringIterator = /** @class */ (function (_super) {\n    __extends(StringIterator, _super);\n    function StringIterator() {\n        return _super !== null && _super.apply(this, arguments) || this;\n    }\n    /**\n     * Splits a string stream on a given separator.\n     *\n     * It is assumed that the incoming chunk boundaries have no semantic meaning,\n     * so conceptually the incoming stream is treated simply as the concatenation\n     * of its elements.\n     *\n     * The outgoing stream provides chunks corresponding to the results of the\n     * standard string split() operation (even if such a chunk spanned incoming\n     * chunks).  The separators are not included.\n     *\n     * A typical usage is to split a text file (represented as a stream with\n     * arbitrary chunk boundaries) into lines.\n     *\n     * @param upstream A readable stream of strings that can be treated as\n     *   concatenated.\n     * @param separator A character to split on.\n     */\n    StringIterator.prototype.split = function (separator) {\n        return new SplitIterator(this, separator);\n    };\n    return StringIterator;\n}(lazy_iterator_1.LazyIterator));\nexports.StringIterator = StringIterator;\n// ============================================================================\n// The following private classes serve to implement the chainable methods\n// on StringIterator.  Unfortunately they can't be placed in separate files, due\n// to resulting trouble with circular imports.\n// ============================================================================\n// We wanted multiple inheritance, e.g.\n//   class SplitIterator extends QueueIterator<string>, StringIterator\n// but the TypeScript mixin approach is a bit hacky, so we take this adapter\n// approach instead.\nvar SplitIterator = /** @class */ (function (_super) {\n    __extends(SplitIterator, _super);\n    function SplitIterator(upstream, separator) {\n        var _this = _super.call(this) || this;\n        _this.upstream = upstream;\n        _this.impl = new SplitIteratorImpl(upstream, separator);\n        return _this;\n    }\n    SplitIterator.prototype.summary = function () {\n        return this.impl.summary();\n    };\n    SplitIterator.prototype.next = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                return [2 /*return*/, this.impl.next()];\n            });\n        });\n    };\n    return SplitIterator;\n}(StringIterator));\nvar SplitIteratorImpl = /** @class */ (function (_super) {\n    __extends(SplitIteratorImpl, _super);\n    function SplitIteratorImpl(upstream, separator) {\n        var _this = _super.call(this) || this;\n        _this.upstream = upstream;\n        _this.separator = separator;\n        // A partial string at the end of an upstream chunk\n        _this.carryover = '';\n        return _this;\n    }\n    SplitIteratorImpl.prototype.summary = function () {\n        return this.upstream.summary() + \" -> Split('\" + this.separator + \"')\";\n    };\n    SplitIteratorImpl.prototype.pump = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var chunkResult, lines, _i, _a, line;\n            return __generator(this, function (_b) {\n                switch (_b.label) {\n                    case 0: return [4 /*yield*/, this.upstream.next()];\n                    case 1:\n                        chunkResult = _b.sent();\n                        if (chunkResult.done) {\n                            if (this.carryover === '') {\n                                return [2 /*return*/, false];\n                            }\n                            // Pretend that the pump succeeded in order to emit the small last batch.\n                            // The next pump() call will actually fail.\n                            this.outputQueue.push(this.carryover);\n                            this.carryover = '';\n                            return [2 /*return*/, true];\n                        }\n                        lines = chunkResult.value.split(this.separator);\n                        // Note the behavior: \" ab \".split(' ') === ['', 'ab', '']\n                        // Thus the carryover may be '' if the separator falls on a chunk\n                        // boundary; this produces the correct result.\n                        lines[0] = this.carryover + lines[0];\n                        for (_i = 0, _a = lines.slice(0, -1); _i < _a.length; _i++) {\n                            line = _a[_i];\n                            this.outputQueue.push(line);\n                        }\n                        this.carryover = lines[lines.length - 1];\n                        return [2 /*return*/, true];\n                }\n            });\n        });\n    };\n    return SplitIteratorImpl;\n}(lazy_iterator_1.OneToManyIterator));\n//# sourceMappingURL=string_iterator.js.map","\"use strict\";\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n// Skip tslint any type check cause this method is aiming to check type of\n// input.\n// tslint:disable-next-line:no-any\nfunction isLocalPath(source) {\n    return (typeof source === 'string') && source.substr(0, 7) === 'file://';\n}\nexports.isLocalPath = isLocalPath;\n//# sourceMappingURL=source_util.js.map","\"use strict\";\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tfjs_core_1 = require(\"@tensorflow/tfjs-core\");\nvar datasource_1 = require(\"../datasource\");\nvar file_chunk_iterator_1 = require(\"../iterators/file_chunk_iterator\");\nvar source_util_1 = require(\"../util/source_util\");\n/**\n * Represents a file, blob, or Uint8Array readable as a stream of binary data\n * chunks.\n */\nvar FileDataSource = /** @class */ (function (_super) {\n    __extends(FileDataSource, _super);\n    /**\n     * Create a `FileDataSource`.\n     *\n     * @param input Local file path, or `File`/`Blob`/`Uint8Array` object to\n     *     read. Local file only works in node environment.\n     * @param options Options passed to the underlying `FileChunkIterator`s,\n     *   such as {chunksize: 1024}.\n     */\n    function FileDataSource(input, options) {\n        if (options === void 0) { options = {}; }\n        var _this = _super.call(this) || this;\n        _this.input = input;\n        _this.options = options;\n        return _this;\n    }\n    FileDataSource.prototype.iterator = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var fs;\n            return __generator(this, function (_a) {\n                if (source_util_1.isLocalPath(this.input) && tfjs_core_1.ENV.get('IS_NODE')) {\n                    fs = require('fs');\n                    this.input = fs.readFileSync(this.input.substr(7));\n                }\n                // TODO(kangyizhang): Add LocalFileChunkIterator to split local streaming\n                // with file in browser.\n                return [2 /*return*/, new file_chunk_iterator_1.FileChunkIterator(this.input, this.options)];\n            });\n        });\n    };\n    return FileDataSource;\n}(datasource_1.DataSource));\nexports.FileDataSource = FileDataSource;\n//# sourceMappingURL=file_data_source.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/** @license See the LICENSE file. */\n// This code is auto-generated, do not modify this file!\nvar version = '1.0.3';\nexports.version = version;\n//# sourceMappingURL=version.js.map"]}